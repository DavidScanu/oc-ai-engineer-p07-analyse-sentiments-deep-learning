{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 7 - R√©alisez une analyse de sentiments gr√¢ce au Deep Learning\n",
    "\n",
    "> üéì OpenClassrooms ‚Ä¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | üëã *√âtudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)\n",
    "\n",
    "## Partie 2 : Approches classiques de Machine Learning\n",
    "\n",
    "Ce notebook impl√©mente plusieurs mod√®les de **machine learning traditionnels pour la classification de sentiment des tweets**. Nous commen√ßons par un pr√©traitement adapt√© aux sp√©cificit√©s des tweets (URLs, mentions, hashtags), puis nous vectorisons les textes avec les approches **BoW** et **TF-IDF**. Quatre classifieurs sont test√©s et compar√©s : **R√©gression Logistique, SVM, Random Forest et Naive Bayes**. Les performances de chaque mod√®le sont mesur√©es (accuracy, precision, recall, F1-score) et enregistr√©es via **MLflow** pour faciliter la comparaison. Le meilleur mod√®le est automatiquement sauvegard√© pour une utilisation ult√©rieure dans l'API.\n",
    "\n",
    "## üìù Contexte\n",
    "\n",
    "Dans le cadre de ma formation d'AI Engineer chez OpenClassrooms, ce projet s'inscrit dans un sc√©nario professionnel o√π j'interviens en tant qu'ing√©nieur IA chez MIC (Marketing Intelligence Consulting), entreprise de conseil sp√©cialis√©e en marketing digital.\n",
    "\n",
    "Notre client, Air Paradis (compagnie a√©rienne), souhaite **anticiper les bad buzz sur les r√©seaux sociaux**. La mission consiste √† d√©velopper un produit IA permettant de **pr√©dire le sentiment associ√© √† un tweet**, afin d'am√©liorer la gestion de sa r√©putation en ligne.\n",
    "\n",
    "## ‚ö° Mission\n",
    "\n",
    "> D√©velopper un mod√®le d'IA permettant de pr√©dire le sentiment associ√© √† un tweet.\n",
    "\n",
    "Cr√©er un prototype fonctionnel d'un mod√®le d'**analyse de sentiments pour tweets** selon trois approches diff√©rentes :\n",
    "\n",
    "1. **Mod√®le sur mesure simple** : Approche classique (r√©gression logistique) pour une pr√©diction rapide\n",
    "2. **Mod√®le sur mesure avanc√©** : Utilisation de r√©seaux de neurones profonds avec diff√©rents word embeddings\n",
    "3. **Mod√®le avanc√© BERT** : Exploration de l'apport en performance d'un mod√®le BERT\n",
    "\n",
    "Cette mission implique √©galement la mise en ≈ìuvre d'une d√©marche MLOps compl√®te :\n",
    "- Utilisation de MLFlow pour le tracking des exp√©rimentations et le stockage des mod√®les\n",
    "- Cr√©ation d'un pipeline de d√©ploiement continu (Git + Github + plateforme Cloud)\n",
    "- Int√©gration de tests unitaires automatis√©s\n",
    "- Mise en place d'un suivi de performance en production via Azure Application Insight\n",
    "\n",
    "## üóìÔ∏è Plan de travail\n",
    "\n",
    "1. **Exploration et pr√©paration des donn√©es**\n",
    "   - Acquisition des donn√©es de tweets Open Source\n",
    "   - Analyse exploratoire et pr√©traitement des textes\n",
    "\n",
    "2. **D√©veloppement des mod√®les**\n",
    "   - Impl√©mentation du mod√®le classique (r√©gression logistique)\n",
    "   - Conception du mod√®le avanc√© avec diff√©rents word embeddings\n",
    "   - Test du mod√®le BERT pour l'analyse de sentiments\n",
    "   - Comparaison des performances via MLFlow\n",
    "\n",
    "3. **Mise en place de la d√©marche MLOps**\n",
    "   - Configuration de MLFlow pour le tracking des exp√©rimentations\n",
    "   - Cr√©ation du d√©p√¥t Git avec structure de projet appropri√©e\n",
    "   - Impl√©mentation des tests unitaires automatis√©s\n",
    "   - Configuration du pipeline de d√©ploiement continu\n",
    "\n",
    "4. **D√©ploiement et monitoring**\n",
    "   - D√©veloppement de l'API de pr√©diction avec FastAPI\n",
    "   - D√©ploiement sur Heroku\n",
    "   - Cr√©ation de l'interface de test (Streamlit ou Next.js)\n",
    "   - Configuration du suivi via Azure Application Insight\n",
    "\n",
    "5. **Communication**\n",
    "   - R√©daction de l'article de blog\n",
    "   - Pr√©paration du support de pr√©sentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/david/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/david/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importations n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importations NLTK\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Importations scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             fbeta_score, make_scorer, matthews_corrcoef, balanced_accuracy_score,\n",
    "                             classification_report, confusion_matrix, roc_auc_score, roc_curve)\n",
    "\n",
    "# Configuration des visualisations\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Jeu de donn√©es : Sentiment140\n",
    "\n",
    "Le jeu de donn√©es [Sentiment140 dataset with 1.6 million tweets](https://www.kaggle.com/datasets/kazanova/sentiment140) est une ressource majeure pour l'analyse de sentiment sur Twitter, comprenant **1,6 million de tweets** extraits via l'API Twitter. Ces tweets ont √©t√© automatiquement annot√©s selon leur polarit√© sentimentale, offrant une base solide pour d√©velopper des mod√®les de classification de sentiment.\n",
    "\n",
    "Le jeu de donn√©es est organis√© en 6 colonnes distinctes :\n",
    "\n",
    "1. **target** : La polarit√© du sentiment exprim√© dans le tweet.\n",
    "   - 0 = sentiment n√©gatif\n",
    "   - 2 = sentiment neutre\n",
    "   - 4 = sentiment positif\n",
    "2. **ids** : L'identifiant unique du tweet (exemple : *2087*)\n",
    "3. **date** : La date et l'heure de publication du tweet.\n",
    "4. **flag** : La requ√™te utilis√©e pour obtenir le tweet.\n",
    "   - Exemple : *lyx*\n",
    "   - Si aucune requ√™te n'a √©t√© utilis√©e : *NO_QUERY*\n",
    "5. **user** : Le nom d'utilisateur de l'auteur du tweet.\n",
    "6. **text** : Le contenu textuel du tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 Œºs, sys: 5 Œºs, total: 55 Œºs\n",
      "Wall time: 60.3 Œºs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Define the URL and the local file path\n",
    "url = \"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip\"\n",
    "local_zip_path = \"./content/data/sentiment140.zip\"\n",
    "extract_path = \"./content/data\"\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    # Download the zip file\n",
    "    response = requests.get(url)\n",
    "    with open(local_zip_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    # Delete the zip file\n",
    "    os.remove(local_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag             user                                               text\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton  is upset that he can't update his Facebook by ...\n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus  @Kenichan I dived many times for the ball. Man...\n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF    my whole body feels itchy and like its on fire \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = os.path.join(extract_path, 'training.1600000.processed.noemoticon.csv')\n",
    "\n",
    "# Define the column names\n",
    "column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "raw_data = pd.read_csv(csv_file_path, encoding='latin-1', names=column_names)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce dataframe contient 1600000 lignes et 6 colonnes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ce dataframe contient {raw_data.shape[0]} lignes et {raw_data.shape[1]} colonnes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandations de mod√©lisation\n",
    "\n",
    "Approches recommand√©es pour l'analyse de sentiment:\n",
    "\n",
    "1. Approches classiques de Machine Learning:\n",
    "   - Mod√®les bas√©s sur les sacs de mots (BoW) ou TF-IDF avec classifieurs comme R√©gression Logistique, SVM, Random Forest ou Naive Bayes\n",
    "\n",
    "2. Word Embeddings + Deep Learning (2 mod√®les):\n",
    "   - Utiliser des embeddings pr√©-entra√Æn√©s (Word2Vec, GloVe, FastText) avec des classifieurs Deep Learning\n",
    "   - Utiliser des r√©seaux de neurones r√©currents (RNN, **LSTM**, GRU)\n",
    "\n",
    "3. Mod√®les transformers (BERT, Sentence Transformers, RoBERTa, DistilBERT):\n",
    "   - Fine-tuning de mod√®les pr√©-entra√Æn√©s sp√©cifiques √† Twitter comme BERTweet\n",
    "\n",
    "Consid√©rations importantes:\n",
    "\n",
    "1. D√©s√©quilibre des classes: utiliser des techniques comme SMOTE, sous-√©chantillonnage, ou pond√©ration des classes\n",
    "2. Validation crois√©e: essentielle pour √©valuer correctement les performances\n",
    "3. M√©triques d'√©valuation: ne pas se limiter √† l'accuracy, utiliser F1-score, pr√©cision, rappel, et AUC-ROC\n",
    "4. Interpr√©tabilit√©: pour certaines applications, privil√©gier des mod√®les interpr√©tables ou utiliser SHAP/LIME\n",
    "5. D√©pendance temporelle: consid√©rer l'√©volution du langage sur Twitter au fil du temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes du mentor :**\n",
    "\n",
    "Voici le texte extrait de cette capture d'√©cran :\n",
    "\n",
    "- Cr√©ation de deux mod√®les de Deep Learning, dont au moins un avec un layer LSTM.\n",
    "- Simulation selon deux techniques de pr√©-traitement (lemmatization, stemming) sur l'un des 2 mod√®les, afin de choisir la technique pour la suite des simulations.\n",
    "- Simulation selon 2 approches de word embedding (parmi Word2VEc, Glove, FastText), entra√Æn√©s avec le jeu de donn√©es ou pr√©-entra√Æn√©s sur au moins un des 2 mod√®les de Deep Learning, afin de choisir l'embedding pour la suite des simulations.\n",
    "- Cr√©ation ensuite d'un mod√®le BERT, il y a 2 approches possibles :\n",
    "  - G√©n√©rer des features (sentence embedding) √† partir d'un TFBertModel (Hugging Face) ou d'un d'un model via le Hub TensorFlow, puis ajouter une ou des couches de classification\n",
    "  - Utiliser directement un mod√®le Hugging Face de type TFBertForSequenceClassification\n",
    "- En option tester USE (Universal Sentence Encoding) pour le feature engineering\n",
    "\n",
    "Probl√®mes et erreurs courants :\n",
    "- Temps de traitement et limitation de ressources en TensorFlow-Keras.\n",
    "- Inspirer des exemples de mod√®les cit√©s en ressources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approches classiques de Machine Learning\n",
    "\n",
    "Notre d√©marche pour la classification de sentiment avec des approches classiques comprend:\n",
    "\n",
    "1. **Pr√©traitement des tweets**\n",
    "   - Nettoyage: suppression des caract√®res sp√©ciaux\n",
    "   - Tokenisation et lemmatisation\n",
    "   - Remplacement des URLs et mentions par des tokens sp√©ciaux\n",
    "\n",
    "2. **Vectorisation du texte**\n",
    "   - **Sac de mots (BoW)** : repr√©sentation bas√©e sur la fr√©quence d'apparition\n",
    "   - **TF-IDF** : pond√©ration par importance relative des mots\n",
    "\n",
    "3. **Mod√®les test√©s**\n",
    "   - R√©gression Logistique: rapide et interpr√©table\n",
    "   - SVM Lin√©aire: efficace pour les textes\n",
    "   - Random Forest: robuste aux outliers\n",
    "   - Naive Bayes: performant pour les classifications textuelles\n",
    "\n",
    "4. **√âvaluation et suivi**\n",
    "   - M√©triques: accuracy, pr√©cision, recall, F1-score\n",
    "   - Tracking avec MLflow pour la reproductibilit√© et la comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentiment_label(df):\n",
    "    converted_target_data = df.copy()\n",
    "    converted_target_data['target'] = converted_target_data['target'].apply(lambda x: 0 if x == 0 else 1)\n",
    "    return converted_target_data\n",
    "\n",
    "converted_target_data = convert_sentiment_label(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_target_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    50000\n",
       "1    50000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def downsample_data(df, n_samples=50000):\n",
    "    \"\"\"\n",
    "    R√©duit la taille d'un DataFrame en √©chantillonnant al√©atoirement un nombre sp√©cifi√© de lignes pour chaque classe.\n",
    "    \"\"\"\n",
    "    negative_samples = df[df['target'] == 0].sample(n=n_samples, random_state=42)\n",
    "    positive_samples = df[df['target'] == 1].sample(n=n_samples, random_state=42)\n",
    "    downsampled_data = pd.concat([negative_samples, positive_samples])\n",
    "    return downsampled_data\n",
    "\n",
    "downsampled_data = downsample_data(converted_target_data, n_samples=50000)\n",
    "downsampled_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# Fonction de pr√©traitement pour les tweets\n",
    "def preprocess_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Pr√©traite un tweet en appliquant plusieurs transformations :\n",
    "    - Conversion en minuscules\n",
    "    - Remplacement des URLs, mentions et hashtags par des tokens sp√©ciaux\n",
    "    - Suppression des caract√®res sp√©ciaux\n",
    "    - Tokenisation et lemmatisation\n",
    "    - Suppression des stopwords\n",
    "    \"\"\"\n",
    "    # V√©rifier si le tweet est une cha√Æne de caract√®res\n",
    "    if not isinstance(tweet, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convertir en minuscules\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remplacer les URLs par un token sp√©cial\n",
    "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', tweet)\n",
    "    \n",
    "    # Remplacer les mentions par un token sp√©cial\n",
    "    tweet = re.sub(r'@\\w+', '<MENTION>', tweet)\n",
    "    \n",
    "    # Traiter les hashtags (conserver le # comme token s√©par√© et le mot qui suit)\n",
    "    tweet = re.sub(r'#(\\w+)', r'# \\1', tweet)\n",
    "    \n",
    "    # Supprimer les caract√®res sp√©ciaux et les nombres, mais garder les tokens sp√©ciaux\n",
    "    tweet = re.sub(r'[^\\w\\s<>@#!?]', '', tweet)\n",
    "    \n",
    "    # Tokenisation\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Supprimer les stopwords, mais conserver les n√©gations importantes\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    important_words = {'no', 'not', 'nor', 'neither', 'never', 'nobody', 'none', 'nothing', 'nowhere'}\n",
    "    stop_words = stop_words - important_words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Rejoindre les tokens en une cha√Æne\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def process_in_parallel(df, func, n_jobs=4):\n",
    "    \"\"\"\n",
    "    Applique une fonction √† un DataFrame en le divisant en parties et en traitant chaque partie en parall√®le.\n",
    "    Permet d'acc√©l√©rer le traitement sur les ordinateurs multi-coeurs.\n",
    "    \"\"\"\n",
    "    df_split = np.array_split(df, n_jobs)\n",
    "    pool = Pool(n_jobs)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def apply_preprocessing(df_part):\n",
    "    df_part['processed_text'] = df_part['text'].apply(preprocess_tweet)\n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√©traitement des tweets en cours...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√©traitement termin√© !\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le pr√©traitement √† tous les tweets\n",
    "print(\"Pr√©traitement des tweets en cours...\")\n",
    "# downsampled_data['processed_text'] = downsampled_data['text'].apply(preprocess_tweet)\n",
    "# Utilisation\n",
    "preprocessed_data = process_in_parallel(downsampled_data, apply_preprocessing, n_jobs=8)\n",
    "print(\"Pr√©traitement termin√© !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212188</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>&lt; MENTION &gt; oh no ! u order ? thats horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299036</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>great hard training weekend couple day rest le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475978</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right work 5 hour go im free xd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588988</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>craving japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138859</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow got ta work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag            user                                               text                                     processed_text\n",
       "212188       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98  @xnausikaax oh no! where did u order from? tha...       < MENTION > oh no ! u order ? thats horrible\n",
       "299036       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76  A great hard training weekend is over.  a coup...  great hard training weekend couple day rest le...\n",
       "475978       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x  Right, off to work  Only 5 hours to go until I...                    right work 5 hour go im free xd\n",
       "588988       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi                    I am craving for japanese food                               craving japanese food\n",
       "138859       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson  Jean Michel Jarre concert tomorrow  gotta work...  jean michel jarre concert tomorrow got ta work..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division des donn√©es en ensembles d'entra√Ænement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entra√Ænement: 80000 exemples\n",
      "Taille de l'ensemble de test: 20000 exemples\n"
     ]
    }
   ],
   "source": [
    "# Diviser les donn√©es en ensembles d'entra√Ænement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocessed_data['processed_text']\n",
    "y = preprocessed_data['target']\n",
    "\n",
    "# Division train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Taille de l'ensemble d'entra√Ænement: {X_train.shape[0]} exemples\")\n",
    "print(f\"Taille de l'ensemble de test: {X_test.shape[0]} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entra√Ænement des mod√®les et tracking avec MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration de MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: https://zany-orbit-q59ppqxj6j34j4x-5001.app.github.dev/\n",
      "Identifiants AWS configur√©s\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration de MLflow avec les variables d'environnement\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Configuration explicite de MLflow\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "print(f\"MLflow Tracking URI: {mlflow_tracking_uri}\")\n",
    "\n",
    "# Configuration explicite des identifiants AWS\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key_id\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_access_key\n",
    "print(\"Identifiants AWS configur√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artefact-store/models/52', creation_time=1741945848821, experiment_id='52', last_update_time=1741945848821, lifecycle_stage='active', name='OC Projet 7', tags={}>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er l'exp√©rience MLflow\n",
    "mlflow.set_experiment(\"OC Projet 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation des textes\n",
    "\n",
    "La vectorisation est le processus qui transforme des documents textuels en vecteurs num√©riques exploitables par les algorithmes de machine learning. Les deux approches simples sont :\n",
    "\n",
    "- **Bag of Words (BoW)** : compte simplement la fr√©quence d'apparition de chaque mot\n",
    "- **TF-IDF** : pond√®re les mots selon leur importance (fr√©quence dans le document / fr√©quence dans tous les documents)\n",
    "\n",
    "Ces m√©thodes cr√©ent des matrices g√©n√©ralement tr√®s creuses (>99% de z√©ros) car chaque document n'utilise qu'une petite partie du vocabulaire total. Dans notre impl√©mentation, nous utilisons `CountVectorizer` pour l'approche BoW et `TfidfVectorizer` pour le TF-IDF, avec des n-grammes (1,2) qui permettent de capturer des expressions de deux mots cons√©cutifs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorisation termin√©e !\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Cr√©er les vectoriseurs\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "bow_vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "# Transformer les textes en vecteurs TF-IDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Transformer les textes en vecteurs BoW\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Vectorisation termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'√©valuation des mod√®les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le contexte d'un outil pr√©ventif de **d√©tection de bad buzz pour Air Paradis**, il est probablement plus important de **ne pas manquer de tweets n√©gatifs** (priorit√© au rappel), nous pouvons consid√©rer le **F2-score** qui donne plus de poids au rappel qu'√† la pr√©cision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, vectorizer_name):\n",
    "    \"\"\"\n",
    "    √âvalue un mod√®le d√©j√† entra√Æn√© et retourne les r√©sultats\n",
    "    \"\"\"\n",
    "    # Pr√©dictions sur l'ensemble de test\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Obtenir les probabilit√©s ou scores de d√©cision pour ROC AUC\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_score = model.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = y_pred  # Fallback pour les mod√®les qui n'ont pas ces m√©thodes\n",
    "    \n",
    "    # Calculer les m√©triques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)  # Ajout du F2-score\n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "    \n",
    "    # Cr√©er la matrice de confusion sous forme de figure\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)\n",
    "    ax_cm.set_xlabel('Pr√©diction')\n",
    "    ax_cm.set_ylabel('Valeur r√©elle')\n",
    "    ax_cm.set_title(f'Matrice de confusion - {model_name} avec {vectorizer_name}')\n",
    "    \n",
    "    # Cr√©er la courbe ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    fig_roc, ax_roc = plt.subplots(figsize=(8, 6))\n",
    "    ax_roc.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], 'k--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_xlabel('Taux de faux positifs')\n",
    "    ax_roc.set_ylabel('Taux de vrais positifs')\n",
    "    ax_roc.set_title(f'Courbe ROC - {model_name} avec {vectorizer_name}')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    ax_roc.grid(True)\n",
    "    \n",
    "    # Afficher les r√©sultats\n",
    "    print(f\"\\nR√©sultats pour {model_name} avec {vectorizer_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")  # Ajout du F2-score\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nMatrice de confusion:\")\n",
    "    print(cm)\n",
    "    print(\"\\nRapport de classification:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return accuracy, precision, recall, f1, f2, roc_auc, fig_cm, fig_roc, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialiser les mod√®les √† tester\n",
    "\n",
    "Voici la liste des mod√®les que nous allons tester :\n",
    "\n",
    "- R√©gression Logistique\n",
    "- SVM Lin√©aire\n",
    "- For√™t Al√©atoire\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les mod√®les √† tester\n",
    "base_models = {\n",
    "    \"Regression_Logistique\": LogisticRegression(random_state=42),\n",
    "    \"SVM_Lineaire\": LinearSVC(random_state=42),\n",
    "    \"Random_Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Naive_Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# D√©finir les grilles d'hyperparam√®tres pour GridSearchCV\n",
    "param_grids = {\n",
    "    \"Regression_Logistique\": {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'max_iter': [1000],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \"SVM_Lineaire\": {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'max_iter': [1000],\n",
    "        'dual': [True, False]\n",
    "    },\n",
    "    \"Random_Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    \"Naive_Bayes\": {\n",
    "        'alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dictionnaire des vectoriseurs\n",
    "vectorizers = {\n",
    "    \"TF-IDF\": (tfidf_vectorizer, X_train_tfidf, X_test_tfidf),\n",
    "    \"BoW\": (bow_vectorizer, X_train_bow, X_test_bow)\n",
    "}\n",
    "\n",
    "# D√©finir le scorer F2\n",
    "scorers = {\n",
    "    'f2': make_scorer(fbeta_score, beta=2),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'balanced_acc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# Dictionnaire pour stocker les r√©sultats\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester chaque mod√®le avec les deux types de vectorisation\n",
    "total_iterations = len(base_models) * len(vectorizers)\n",
    "progress_bar = tqdm(total=total_iterations, desc=\"Progression globale\")\n",
    "\n",
    "# Tester chaque mod√®le avec les deux types de vectorisation\n",
    "for model_name, base_model in base_models.items():\n",
    "    for vectorizer_name, (vectorizer, X_train_vec, X_test_vec) in vectorizers.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"D√©marrage de GridSearchCV pour {model_name} avec {vectorizer_name}...\")\n",
    "        \n",
    "        # D√©finir la grille de param√®tres et cr√©er GridSearchCV\n",
    "        param_grid = param_grids[model_name]\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model,\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            scoring=scorers,\n",
    "            refit='f2',\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        # D√©marrer le run MLflow\n",
    "        with mlflow.start_run(run_name=f\"Modele_Simple_{model_name}_{vectorizer_name}\"):\n",
    "            # Journaliser les param√®tres g√©n√©raux\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "            mlflow.log_param(\"vectorizer_type\", vectorizer_name)\n",
    "            mlflow.log_param(\"dataset_size\", X_train.shape[0] + X_test.shape[0])\n",
    "            mlflow.log_param(\"train_size\", X_train.shape[0])\n",
    "            mlflow.log_param(\"test_size\", X_test.shape[0])\n",
    "            mlflow.log_param(\"max_features\", 10000)\n",
    "            mlflow.log_param(\"ngram_range\", \"(1, 2)\")\n",
    "            mlflow.log_param(\"scoring_metric\", \"f2_score\")  # Noter que F2 est utilis√©\n",
    "            \n",
    "            # Mesurer le temps d'entra√Ænement\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Entra√Æner avec GridSearchCV\n",
    "            grid_search.fit(X_train_vec, y_train)\n",
    "            \n",
    "            # Calculer le temps d'entra√Ænement\n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Journaliser le temps d'entra√Ænement\n",
    "            mlflow.log_metric(\"training_time\", training_time)\n",
    "            \n",
    "            # R√©cup√©rer et journaliser les meilleurs param√®tres\n",
    "            best_params = grid_search.best_params_\n",
    "            for param, value in best_params.items():\n",
    "                mlflow.log_param(f\"best_{param}\", value)\n",
    "            \n",
    "            # Journaliser le meilleur score de validation crois√©e\n",
    "            mlflow.log_metric(\"best_cv_f2_score\", grid_search.best_score_)\n",
    "            \n",
    "            # R√©cup√©rer le meilleur mod√®le\n",
    "            best_model = grid_search.best_estimator_\n",
    "            \n",
    "            # √âvaluer le meilleur mod√®le sur l'ensemble de test\n",
    "            acc, prec, rec, f1, f2, roc_auc, fig_cm, fig_roc, y_pred = evaluate_model(\n",
    "                best_model, X_train_vec, X_test_vec, y_train, y_test, model_name, vectorizer_name\n",
    "            )\n",
    "            \n",
    "            # Journaliser les m√©triques\n",
    "            mlflow.log_metric(\"accuracy\", acc)\n",
    "            mlflow.log_metric(\"precision\", prec)\n",
    "            mlflow.log_metric(\"recall\", rec)\n",
    "            mlflow.log_metric(\"f1\", f1)\n",
    "            mlflow.log_metric(\"f2\", f2)\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "            \n",
    "            # Journaliser les figures\n",
    "            mlflow.log_figure(fig_cm, \"confusion_matrix.png\")\n",
    "            mlflow.log_figure(fig_roc, \"roc_curve.png\")\n",
    "            plt.close(fig_cm)\n",
    "            plt.close(fig_roc)\n",
    "            \n",
    "            # Journaliser le mod√®le\n",
    "            signature = infer_signature(X_train_vec, y_pred)\n",
    "            mlflow.sklearn.log_model(best_model, \"model\", signature=signature)\n",
    "            \n",
    "            # Sauvegarder et journaliser le vectoriseur\n",
    "            vectorizer_path = f\"vectorizer_{vectorizer_name}.pkl\"\n",
    "            with open(vectorizer_path, \"wb\") as f:\n",
    "                pickle.dump(vectorizer, f)\n",
    "            mlflow.log_artifact(vectorizer_path)\n",
    "            \n",
    "            # Journaliser les r√©sultats d√©taill√©s de GridSearchCV\n",
    "            cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "            cv_results_path = \"cv_results.csv\"\n",
    "            cv_results.to_csv(cv_results_path, index=False)\n",
    "            mlflow.log_artifact(cv_results_path)\n",
    "            \n",
    "            # Cr√©er et journaliser un graphique des r√©sultats de GridSearchCV\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            params = [f\"{k}={v}\" for k, v in best_params.items()]\n",
    "            params_str = \", \".join(params)\n",
    "            \n",
    "            # Extraire les scores moyens pour chaque param√®tre principal\n",
    "            for param in param_grid.keys():\n",
    "                if len(param_grid[param]) > 1:  # Seulement si le param√®tre a plusieurs valeurs\n",
    "                    param_name = f\"param_{param}\"\n",
    "                    if param_name in cv_results.columns:\n",
    "                        # Utiliser la colonne sp√©cifique √† la m√©trique f2 (que vous avez d√©finie comme principale)\n",
    "                        scores_df = cv_results[[param_name, \"mean_test_f2\", \"std_test_f2\"]]\n",
    "                        scores_df = scores_df.sort_values(param_name)\n",
    "                        \n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.errorbar(\n",
    "                            scores_df[param_name].astype(str),\n",
    "                            scores_df[\"mean_test_f2\"],\n",
    "                            yerr=scores_df[\"std_test_f2\"],\n",
    "                            fmt='-o'\n",
    "                        )\n",
    "                        plt.title(f'Scores de validation crois√©e (F2) par {param}')\n",
    "                        plt.xlabel(param)\n",
    "                        plt.ylabel('F2 Score moyen')\n",
    "                        plt.grid(True)\n",
    "                        mlflow.log_figure(plt.gcf(), f\"cv_results_{param}.png\")\n",
    "                        plt.close()\n",
    "            \n",
    "            # Journaliser les features importantes (pour les mod√®les qui le supportent)\n",
    "            if hasattr(best_model, 'coef_'):\n",
    "                # R√©cup√©rer les features les plus importantes\n",
    "                if isinstance(best_model, LogisticRegression) or isinstance(best_model, LinearSVC):\n",
    "                    coefs = best_model.coef_[0]\n",
    "                    if vectorizer_name == \"TF-IDF\":\n",
    "                        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "                    else:\n",
    "                        feature_names = bow_vectorizer.get_feature_names_out()\n",
    "                    \n",
    "                    # Cr√©er un DataFrame avec les coefs et les noms des features\n",
    "                    coefs_df = pd.DataFrame({\n",
    "                        'feature': feature_names,\n",
    "                        'importance': coefs\n",
    "                    })\n",
    "                    \n",
    "                    # Trier par importance absolue\n",
    "                    coefs_df['abs_importance'] = abs(coefs_df['importance'])\n",
    "                    coefs_df = coefs_df.sort_values('abs_importance', ascending=False).head(20)\n",
    "                    \n",
    "                    # Journaliser les features les plus importantes\n",
    "                    top_features_path = \"top_features.csv\"\n",
    "                    coefs_df.to_csv(top_features_path, index=False)\n",
    "                    mlflow.log_artifact(top_features_path)\n",
    "                    \n",
    "                    # Cr√©er un graphique pour visualiser les features les plus importantes\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    sns.barplot(x='importance', y='feature', data=coefs_df.sort_values('importance', ascending=False).head(20))\n",
    "                    plt.title(f'Top 20 features positives')\n",
    "                    plt.tight_layout()\n",
    "                    mlflow.log_figure(plt.gcf(), \"top_positive_features.png\")\n",
    "                    plt.close()\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    sns.barplot(x='importance', y='feature', data=coefs_df.sort_values('importance').head(20))\n",
    "                    plt.title(f'Top 20 features n√©gatives')\n",
    "                    plt.tight_layout()\n",
    "                    mlflow.log_figure(plt.gcf(), \"top_negative_features.png\")\n",
    "                    plt.close()\n",
    "            \n",
    "            # Stocker les r√©sultats pour comparaison\n",
    "            results.append({\n",
    "                \"Mod√®le\": model_name.replace(\"_\", \" \"),\n",
    "                \"Vectorisation\": vectorizer_name,\n",
    "                \"Meilleurs param√®tres\": str(best_params),\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1 Score\": f1,\n",
    "                \"F2 Score\": f2,\n",
    "                \"ROC AUC\": roc_auc,\n",
    "                \"Temps d'entra√Ænement (s)\": training_time\n",
    "            })\n",
    "            \n",
    "            # Afficher les r√©sultats\n",
    "            print(f\"Meilleurs param√®tres: {best_params}\")\n",
    "            print(f\"Meilleur score CV (F2): {grid_search.best_score_:.4f}\")\n",
    "            print(f\"F1 Score sur test: {f1:.4f}\")\n",
    "            print(f\"F2 Score sur test: {f2:.4f}\")\n",
    "            print(f\"ROC AUC sur test: {roc_auc:.4f}\")\n",
    "            print(f\"Temps d'entra√Ænement: {training_time:.2f} secondes\")\n",
    "\n",
    "\n",
    "        # √Ä la fin de chaque it√©ration, mettez √† jour la barre de progression\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(f\"Dernier mod√®le: {model_name} avec {vectorizer_name}\")\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un tableau r√©capitulatif des r√©sultats\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un run sp√©cial pour le r√©capitulatif\n",
    "with mlflow.start_run(run_name=\"Modele_Simple_Recapitulatif\"):\n",
    "    # Journaliser le tableau des r√©sultats\n",
    "    results_path = \"model_comparison_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    mlflow.log_artifact(results_path)\n",
    "    \n",
    "    # Cr√©er et journaliser un graphique de comparaison des performances F1\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plot_data_f1 = results_df.pivot(index='Mod√®le', columns='Vectorisation', values='F1 Score')\n",
    "    ax_f1 = plot_data_f1.plot(kind='bar', rot=0)\n",
    "    plt.title('Comparaison des mod√®les et vectorisations (F1 Score)')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.ylim(0.6, 1.0)\n",
    "    plt.legend(title='Vectorisation')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    for container in ax_f1.containers:\n",
    "        ax_f1.bar_label(container, fmt='%.3f', padding=3)\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), \"model_comparison_f1.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Cr√©er et journaliser un graphique de comparaison des performances F2\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plot_data_f2 = results_df.pivot(index='Mod√®le', columns='Vectorisation', values='F2 Score')\n",
    "    ax_f2 = plot_data_f2.plot(kind='bar', rot=0)\n",
    "    plt.title('Comparaison des mod√®les et vectorisations (F2 Score)')\n",
    "    plt.ylabel('F2 Score')\n",
    "    plt.ylim(0.6, 1.0)\n",
    "    plt.legend(title='Vectorisation')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    for container in ax_f2.containers:\n",
    "        ax_f2.bar_label(container, fmt='%.3f', padding=3)\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), \"model_comparison_f2.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Cr√©er et journaliser un graphique de comparaison des performances ROC AUC\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plot_data_roc = results_df.pivot(index='Mod√®le', columns='Vectorisation', values='ROC AUC')\n",
    "    ax_roc = plot_data_roc.plot(kind='bar', rot=0)\n",
    "    plt.title('Comparaison des mod√®les et vectorisations (ROC AUC)')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.ylim(0.6, 1.0)\n",
    "    plt.legend(title='Vectorisation')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    for container in ax_roc.containers:\n",
    "        ax_roc.bar_label(container, fmt='%.3f', padding=3)\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), \"model_comparison_roc_auc.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Journaliser le meilleur mod√®le selon F2 (puisque c'est notre m√©trique principale maintenant)\n",
    "    best_model_row = results_df.loc[results_df['F2 Score'].idxmax()]\n",
    "    best_model_name = best_model_row['Mod√®le'].replace(\" \", \"_\")\n",
    "    best_vectorizer = best_model_row['Vectorisation']\n",
    "    \n",
    "    print(f\"\\nMeilleur mod√®le (selon F2): {best_model_row['Mod√®le']} avec {best_vectorizer}\")\n",
    "    print(f\"F1 Score: {best_model_row['F1 Score']:.4f}\")\n",
    "    print(f\"F2 Score: {best_model_row['F2 Score']:.4f}\")\n",
    "    print(f\"ROC AUC: {best_model_row['ROC AUC']:.4f}\")\n",
    "    print(f\"Meilleurs param√®tres: {best_model_row['Meilleurs param√®tres']}\")\n",
    "    \n",
    "    # Journaliser des informations sur le meilleur mod√®le\n",
    "    mlflow.log_param(\"best_model\", f\"{best_model_row['Mod√®le']} avec {best_vectorizer}\")\n",
    "    mlflow.log_param(\"best_model_f1\", best_model_row['F1 Score'])\n",
    "    mlflow.log_param(\"best_model_f2\", best_model_row['F2 Score'])\n",
    "    mlflow.log_param(\"best_model_roc_auc\", best_model_row['ROC AUC'])\n",
    "    mlflow.log_param(\"best_model_params\", best_model_row['Meilleurs param√®tres'])\n",
    "    \n",
    "    # Afficher le tableau des r√©sultats\n",
    "    print(\"\\nR√©capitulatif des r√©sultats:\")\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le meilleur mod√®le pour utilisation future\n",
    "def save_best_model(results_df):\n",
    "    best_model_row = results_df.loc[results_df['F2 Score'].idxmax()]  # Utiliser F2 maintenant\n",
    "    best_model_name = best_model_row['Mod√®le'].replace(\" \", \"_\")\n",
    "    best_vectorizer = best_model_row['Vectorisation']\n",
    "    \n",
    "    # Charger le meilleur mod√®le depuis MLflow\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Trouver le run correspondant au meilleur mod√®le\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[mlflow.get_experiment_by_name(\"OC Projet 7\").experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = 'Modele_Simple_{best_model_name}_{best_vectorizer}'\"\n",
    "    )\n",
    "    \n",
    "    if runs:\n",
    "        best_run = runs[0]\n",
    "        run_id = best_run.info.run_id\n",
    "        \n",
    "        # Charger le mod√®le depuis MLflow\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "        best_model = mlflow.sklearn.load_model(model_uri)\n",
    "        \n",
    "        # Charger le vectoriseur depuis les artefacts\n",
    "        client.download_artifacts(run_id, f\"vectorizer_{best_vectorizer}.pkl\", \"./\")\n",
    "        with open(f\"./vectorizer_{best_vectorizer}.pkl\", \"rb\") as f:\n",
    "            vectorizer = pickle.load(f)\n",
    "        \n",
    "        # Cr√©er le dossier de mod√®les s'il n'existe pas\n",
    "        os.makedirs(\"./content/models\", exist_ok=True)\n",
    "        \n",
    "        # Sauvegarder le mod√®le\n",
    "        model_path = f\"./content/models/best_model_{best_model_name}_{best_vectorizer}.pkl\"\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        \n",
    "        # Sauvegarder le vectoriseur\n",
    "        vectorizer_path = f\"./content/models/vectorizer_{best_vectorizer}.pkl\"\n",
    "        with open(vectorizer_path, \"wb\") as f:\n",
    "            pickle.dump(vectorizer, f)\n",
    "        \n",
    "        print(f\"Meilleur mod√®le ({best_model_row['Mod√®le']} avec {best_vectorizer}) sauvegard√© dans le dossier './content/models'\")\n",
    "        print(f\"Chemin du mod√®le: {model_path}\")\n",
    "        print(f\"Chemin du vectoriseur: {vectorizer_path}\")\n",
    "        \n",
    "        # Test du mod√®le charg√©\n",
    "        if best_vectorizer == \"TF-IDF\":\n",
    "            X_test_vec = X_test_tfidf\n",
    "        else:\n",
    "            X_test_vec = X_test_bow\n",
    "            \n",
    "        y_pred = best_model.predict(X_test_vec)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "        print(f\"F1 Score du meilleur mod√®le sauvegard√©: {f1:.4f}\")\n",
    "        print(f\"F2 Score du meilleur mod√®le sauvegard√©: {f2:.4f}\")\n",
    "        \n",
    "        return best_model, vectorizer, best_model_row['Mod√®le'], best_vectorizer\n",
    "    else:\n",
    "        print(\"Aucun run trouv√© pour le meilleur mod√®le!\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le meilleur mod√®le\n",
    "best_model, vectorizer, best_model_name, best_vectorizer = save_best_model(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de pr√©diction pour l'API\n",
    "def predict_sentiment(text, model=best_model, vect=vectorizer):\n",
    "    \"\"\"\n",
    "    Fonction qui prend un texte en entr√©e et retourne la pr√©diction du sentiment\n",
    "    Cette fonction pourra √™tre utilis√©e dans l'API\n",
    "    \"\"\"\n",
    "    # Pr√©traiter le texte\n",
    "    processed_text = preprocess_tweet(text)\n",
    "    \n",
    "    # Vectoriser\n",
    "    text_vectorized = vect.transform([processed_text])\n",
    "    \n",
    "    # Pr√©dire\n",
    "    prediction = model.predict(text_vectorized)[0]\n",
    "    \n",
    "    # R√©cup√©rer la probabilit√© si le mod√®le le permet\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probas = model.predict_proba(text_vectorized)[0]\n",
    "        confidence = probas[1] if prediction == 1 else probas[0]\n",
    "    else:\n",
    "        # Pour les mod√®les sans predict_proba, comme SVM\n",
    "        decision = model.decision_function(text_vectorized)[0] if hasattr(model, 'decision_function') else 0\n",
    "        confidence = abs(decision) / 2  # Normaliser d'une certaine fa√ßon\n",
    "    \n",
    "    return {\n",
    "        'sentiment': 'positif' if prediction == 1 else 'n√©gatif',\n",
    "        'score': float(confidence),\n",
    "        'model': best_model_name,\n",
    "        'vectorizer': best_vectorizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter des emojis, caract√®res sp√©ciaux, ponctuations, fautes d'orthographe, langage internet (lol, wtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester la fonction de pr√©diction sur quelques exemples\n",
    "def test_model_on_examples(model, vectorizer):\n",
    "    # Quelques exemples de tweets pour tester le mod√®le\n",
    "    test_tweets = [\n",
    "        \"I love this flight, the service was amazing! #happy\",\n",
    "        \"Worst flight ever, delayed for 3 hours and no explanation @airline\",\n",
    "        \"Nice plane but the food was not good enough.\",\n",
    "        \"The staff was helpful but the seats were uncomfortable for a long flight\",\n",
    "        \"Amazing experience with Air Paradis today! Great customer service!\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTest du meilleur mod√®le sur quelques exemples:\")\n",
    "    for i, tweet in enumerate(test_tweets):\n",
    "        result = predict_sentiment(tweet, model, vectorizer)\n",
    "        print(f\"Tweet {i+1}: {tweet}\")\n",
    "        print(f\"Sentiment pr√©dit: {result['sentiment']} (score de confiance: {result['score']:.4f})\\n\")\n",
    "\n",
    "# Ex√©cuter les tests si le mod√®le a √©t√© correctement charg√©\n",
    "if best_model is not None and vectorizer is not None:\n",
    "    test_model_on_examples(best_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion et √©tapes suivantes\n",
    "print(\"\"\"\n",
    "## Conclusion de l'approche \"Mod√®le Simple\"\n",
    "\n",
    "Nous avons d√©velopp√© plusieurs mod√®les classiques pour la d√©tection de sentiment dans les tweets,\n",
    "en utilisant une optimisation des hyperparam√®tres via GridSearchCV optimis√©e sur le F2-score\n",
    "pour privil√©gier le rappel (capacit√© √† ne pas manquer de tweets n√©gatifs) :\n",
    "\n",
    "1. R√©gression Logistique\n",
    "2. SVM Lin√©aire\n",
    "3. Random Forest\n",
    "4. Naive Bayes\n",
    "\n",
    "Chaque mod√®le a √©t√© test√© avec deux types de vectorisation :\n",
    "- Sac de mots (BoW)\n",
    "- TF-IDF\n",
    "\n",
    "Le meilleur mod√®le selon le F2-score est {best_model_name} avec la vectorisation {best_vectorizer}, \n",
    "atteignant un F2 Score de {best_f2:.4f}, un F1 Score de {best_f1:.4f} et un ROC AUC de {best_roc_auc:.4f}.\n",
    "\n",
    "Les hyperparam√®tres optimaux trouv√©s pour ce mod√®le sont : {best_params}\n",
    "\n",
    "### Avantages du workflow impl√©ment√© :\n",
    "\n",
    "1. **Focalisation sur le rappel avec F2-score** :\n",
    "   - R√©duit le risque de manquer des tweets n√©gatifs (bad buzz potentiels)\n",
    "   - Particuli√®rement adapt√© pour l'anticipation des probl√®mes de r√©putation\n",
    "\n",
    "2. **Suivi complet des exp√©riences avec MLflow** :\n",
    "   - Tracking de toutes les m√©triques importantes\n",
    "   - Sauvegarde des mod√®les et vectoriseurs\n",
    "   - Visualisations des performances\n",
    "\n",
    "3. **Optimisation syst√©matique** :\n",
    "   - Recherche sur grille des meilleurs hyperparam√®tres\n",
    "   - Validation crois√©e pour √©viter le surapprentissage\n",
    "   - Comparaison rigoureuse des performances\n",
    "\n",
    "4. **Pr√©traitement adapt√© aux tweets** :\n",
    "   - Traitement sp√©cifique des URLs, mentions et hashtags\n",
    "   - Conservation des n√©gations et autres √©l√©ments linguistiques importants\n",
    "   - Features suppl√©mentaires bas√©es sur l'analyse des donn√©es\n",
    "\n",
    "### Prochaines √©tapes :\n",
    "\n",
    "1. **D√©velopper le mod√®le sur mesure avanc√©** utilisant des r√©seaux de neurones et des word embeddings\n",
    "2. **Tester l'approche avec BERT** pour comparer les performances\n",
    "3. **D√©ployer le mod√®le via une API** pour le rendre accessible √† d'autres applications\n",
    "4. **Mettre en place le suivi MLOps** pour monitorer les performances du mod√®le en production\n",
    "\n",
    "Le mod√®le actuel servira de r√©f√©rence (baseline) pour √©valuer les am√©liorations apport√©es par \n",
    "les approches plus avanc√©es.\n",
    "\"\"\".format(\n",
    "    best_model_name=best_model_name,\n",
    "    best_vectorizer=best_vectorizer,\n",
    "    best_f1=best_model_row['F1 Score'],\n",
    "    best_f2=best_model_row['F2 Score'],\n",
    "    best_roc_auc=best_model_row['ROC AUC'],\n",
    "    best_params=best_model_row['Meilleurs param√®tres']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explications d√©taill√©es\n",
    "\n",
    "Le code complet int√®gre plusieurs pratiques MLOps avanc√©es:\n",
    "\n",
    "### 1. Optimisation des hyperparam√®tres avec GridSearchCV\n",
    "\n",
    "J'ai impl√©ment√© GridSearchCV pour chaque combinaison de mod√®le et vectoriseur. Cela permet d'explorer syst√©matiquement l'espace des hyperparam√®tres pour trouver la configuration optimale. Pour chaque mod√®le, j'ai d√©fini une grille de param√®tres pertinents:\n",
    "\n",
    "- **R√©gression Logistique**: diff√©rentes valeurs de r√©gularisation (C), types de solveurs\n",
    "- **SVM**: diff√©rentes valeurs de C, options de dualit√©\n",
    "- **Random Forest**: nombre d'arbres, profondeur maximale, crit√®res de division\n",
    "- **Naive Bayes**: diff√©rentes valeurs pour le param√®tre de lissage alpha\n",
    "\n",
    "L'optimisation est effectu√©e avec validation crois√©e √† 5 plis (5-fold) pour garantir la robustesse des r√©sultats.\n",
    "\n",
    "### 2. Tracking complet avec MLflow\n",
    "\n",
    "Pour chaque exp√©rience, j'enregistre dans MLflow:\n",
    "\n",
    "- **Param√®tres**: tous les hyperparam√®tres utilis√©s, y compris les meilleurs trouv√©s par GridSearchCV\n",
    "- **M√©triques**: accuracy, precision, recall, F1 score, ROC AUC, temps d'entra√Ænement\n",
    "- **Artifacts**: \n",
    "  - Le mod√®le optimis√© avec sa signature d'entr√©e/sortie\n",
    "  - Le vectoriseur utilis√© (nouveaut√© demand√©e)\n",
    "  - La matrice de confusion et la courbe ROC\n",
    "  - Les r√©sultats d√©taill√©s de la validation crois√©e\n",
    "  - Les features les plus importantes (pour les mod√®les qui le permettent)\n",
    "  - Des graphiques d'analyse de l'influence des hyperparam√®tres\n",
    "\n",
    "### 3. R√©capitulatif global et analyse comparative\n",
    "\n",
    "Un run sp√©cial \"Recapitulatif\" est cr√©√© pour comparer tous les mod√®les:\n",
    "\n",
    "- Tableau comparatif avec toutes les m√©triques\n",
    "- Graphiques de comparaison pour F1 Score et ROC AUC\n",
    "- Identification et journalisation du meilleur mod√®le\n",
    "\n",
    "### 4. Sauvegarde et utilisation du meilleur mod√®le\n",
    "\n",
    "J'ai impl√©ment√© une m√©thode sophistiqu√©e pour:\n",
    "\n",
    "1. Identifier le meilleur mod√®le dans l'historique MLflow\n",
    "2. Le r√©cup√©rer avec son vectoriseur\n",
    "3. Sauvegarder les deux dans un dossier local sp√©cifi√© (\"./content/models\")\n",
    "4. Cr√©er une fonction de pr√©diction pr√™te pour l'API\n",
    "\n",
    "### 5. Visualisations avanc√©es\n",
    "\n",
    "Pour faciliter l'analyse:\n",
    "\n",
    "- Matrices de confusion pour chaque mod√®le\n",
    "- Courbes ROC avec AUC calcul√©\n",
    "- Graphiques des features les plus importantes\n",
    "- Graphiques d'√©volution des scores en fonction des hyperparam√®tres\n",
    "\n",
    "### Avantages de cette approche\n",
    "\n",
    "1. **Reproductibilit√©**: Tous les d√©tails des exp√©riences sont enregistr√©s\n",
    "2. **Tra√ßabilit√©**: Tu peux facilement suivre l'√©volution des performances\n",
    "3. **Maintenabilit√©**: Le code est modulaire et bien document√©\n",
    "4. **Optimisation automatique**: La recherche des meilleurs hyperparam√®tres est syst√©matique\n",
    "5. **Facilit√© d'int√©gration**: Le mod√®le et vectoriseur sont sauvegard√©s pr√™ts pour le d√©ploiement\n",
    "\n",
    "Cette impl√©mentation suit les bonnes pratiques MLOps et pose des bases solides pour les √©tapes suivantes du projet, notamment le d√©veloppement de mod√®les plus avanc√©s et leur d√©ploiement.\n",
    "\n",
    "### Prochaines √©tapes :\n",
    "\n",
    "1. **D√©velopper le mod√®le sur mesure avanc√©** utilisant des r√©seaux de neurones et des word embeddings\n",
    "2. **Tester l'approche avec BERT** pour comparer les performances\n",
    "3. **D√©ployer le mod√®le via une API** pour le rendre accessible √† d'autres applications\n",
    "4. **Mettre en place le suivi MLOps** pour monitorer les performances du mod√®le en production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
