# üí¨‚ù§Ô∏è Analyse de Sentiments de Tweets gr√¢ce au Deep Learning : Une Approche MLOps

> Cet article est disponible en ligne : [https://dev.to/davidscanu/analyse-de-sentiments-de-tweets-grace-au-deep-learning-une-approche-mlops-3ib7](https://dev.to/davidscanu/analyse-de-sentiments-de-tweets-grace-au-deep-learning-une-approche-mlops-3ib7)

![People tweeting](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9g3e3jg9j9o56ifjz9af.png)

*Cet article a √©t√© r√©dig√© dans le cadre du projet : R√©alisez une analyse de sentiments gr√¢ce au Deep Learning du parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) d'[OpenClassrooms](https://openclassrooms.com/f). Les donn√©es utilis√©es sont issues du jeu de donn√©es open source [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140). Le code source complet est disponible sur [GitHub](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning).*

> üéì OpenClassrooms ‚Ä¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | üëã *√âtudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)

![Application De pr√©diction de tweet d'Air Paradis](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/slbftyfpuhwkis2qr5w4.png)

## üåê Contexte et probl√©matique m√©tier 

Dans le cadre de ma formation d'[AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) chez [OpenClassrooms](https://openclassrooms.com/fr/), ce projet s'inscrit dans un sc√©nario professionnel o√π j'interviens en tant qu'ing√©nieur IA chez MIC (Marketing Intelligence Consulting), entreprise de conseil sp√©cialis√©e en marketing digital.

Notre client, **‚úàÔ∏è Air Paradis** (compagnie a√©rienne), souhaite **anticiper les bad buzz sur les r√©seaux sociaux**. La mission consiste √† d√©velopper un produit IA permettant de pr√©dire le sentiment associ√© √† un tweet, afin d'am√©liorer la gestion de sa r√©putation en ligne.

## ‚ö° Mission

> D√©velopper un mod√®le d'IA permettant de pr√©dire le sentiment associ√© √† un tweet.

Cr√©er un prototype fonctionnel d'un mod√®le d'analyse de sentiments pour tweets selon trois approches diff√©rentes :

1. **Mod√®le sur mesure simple** : Approche classique (r√©gression logistique) pour une pr√©diction rapide
2. **Mod√®le sur mesure avanc√©** : Utilisation de r√©seaux de neurones profonds avec diff√©rents word embeddings
3. **Mod√®le avanc√© BERT** : Exploration de l'apport en performance d'un mod√®le BERT

Cette mission implique √©galement la mise en ≈ìuvre d'une **d√©marche MLOps compl√®te** :

- Utilisation de **MLFlow pour le tracking des exp√©rimentations et le stockage des mod√®les**.
- Cr√©ation d'un **pipeline de d√©ploiement continu** (Git + Github + plateforme Cloud).
- Int√©gration de **tests unitaires automatis√©s**.
- Mise en place d'un **suivi de performance en production** via Azure A[pplication Insight](https://learn.microsoft.com/fr-fr/azure/azure-monitor/app/app-insights-overview).

## üîß Technologies utilis√©es

- **Langages** : Python
- **Biblioth√®ques ML/DL** : Scikit-learn, TensorFlow/Keras, Transformers (BERT)
- **MLOps** : MLFlow, Git, GitHub Actions
- **Backend** : FastAPI, Heroku
- **Frontend** : Next.js / React
- **Monitoring** : Azure Application Insight
- **Traitement texte** : NLTK, Word Embeddings

## üèõÔ∏è Structure du projet

```
üì¶ oc-ai-engineer-p07-analyse-sentiments-deep-learning/
‚î£‚îÅ‚îÅ üìÇ app/
‚îÉ   ‚î£‚îÅ‚îÅ üìÇ fastapi/                         # Backend API de pr√©diction
‚îÉ   ‚îó‚îÅ‚îÅ üìÇ frontend/                        # Application Next.js
‚îÉ
‚î£‚îÅ‚îÅ üìÇ documentation/                       # Documentation du projet
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ guide-app-insights.md            # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ
‚îó‚îÅ‚îÅ üìÇ notebooks/                           # Notebooks Jupyter pour l'analyse et mod√®les
    ‚î£‚îÅ‚îÅ üìù 01_Analyse_exploratoire.ipynb     # Exploration et visualisation des donn√©es
    ‚î£‚îÅ‚îÅ üìù 02_Modele_simple.ipynb            # Bag of Words et classificateurs classiques
    ‚î£‚îÅ‚îÅ üìù 03_Modele_avance_Word2Vec.ipynb   # LSTM avec Word2Vec
    ‚îó‚îÅ‚îÅ üìù 04_Modele_BERT.ipynb              # DistilBERT pour analyse de sentiment
```

## üìî Notebooks du projet

- [üìä Notebook 1 : Analyse exploratoire des donn√©es](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning/blob/main/notebooks/scanu-david-01-notebook-analyse-exploratoire-20250306.ipynb) - Exploration du dataset Sentiment140 et visualisations
- [üîç Notebook 2 : Mod√®le classique (TF-IDF + Regression Logistique)](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning/blob/main/notebooks/scanu-david-02-notebook-modele-simple-20250306.ipynb) - Impl√©mentation de l'approche "sur mesure simple"
- [üß† Notebook 3 : Mod√®le avanc√© (Word2Vec + LSTM)](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning/blob/main/notebooks/scanu-david-03-notebook-modele-avance-20250306.ipynb) - R√©seau de neurones avec word embeddings
- [üöÄ Notebook 4 : Mod√®le BERT pour l'analyse de sentiment](https://colab.research.google.com/drive/1TFq3selzmDCTReGfa2NvvlaNSRZMhdzY?usp=sharing) - Fine-tuning de DistilBERT (Google Colab)

## üß≠ Guides

- [Guide d'utilisation de l'API FastAPI](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning/blob/main/app/fastapi/README.md) : API FastAPI qui expose un mod√®le de deep learning pour l'analyse de sentiment
- [Guide d'utilisation du frontend Next.JS](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning/blob/main/app/frontend/README.md) : Application Next.js avec Bootstrap pour l'interface utilisateur
- [Guide de Monitoring pour Air Paradis](https://github.com/DavidScanu/oc-ai-engineer-p07-analyse-sentiments-deep-learning/blob/main/documentation/guide-app-insights.md) : Mise en place du feedback utilisateur et des alertes avec Azure Application insights

## üìë M√©thodologie et donn√©es

### Le jeu de donn√©es Sentiment140

Pour ce projet, nous avons utilis√© le jeu de donn√©es open source Sentiment140, qui contient 1,6 million de tweets annot√©s selon leur polarit√© (n√©gative ou positive). Ce dataset comprend six champs principaux :

- **target** : la polarit√© du tweet (0 = n√©gatif, 4 = positif)
- **ids** : l'identifiant du tweet
- **date** : la date du tweet
- **flag** : une requ√™te √©ventuelle
- **user** : l'utilisateur ayant post√© le tweet
- **text** : le contenu textuel du tweet

Nous avons choisi ce jeu de donn√©es pour sa taille cons√©quente et sa pertinence vis-√†-vis de notre objectif d'analyse de sentiments sur Twitter. Sa structure binaire (positif/n√©gatif) correspond parfaitement √† notre besoin de d√©tecter les opinions n√©gatives pouvant potentiellement nuire √† l'image d'Air Paradis.

### Analyse exploratoire des donn√©es Sentiment140

Notre analyse exploratoire a r√©v√©l√© des caract√©ristiques distinctives importantes entre les tweets positifs et n√©gatifs :

- Les tweets positifs contiennent **93% plus d'URLs** que les n√©gatifs
- Les tweets positifs contiennent **48% plus de mentions (@)**
- Les tweets positifs utilisent **39% plus de hashtags (#)**
- Les tweets positifs utilisent **39% plus de points d'exclamation (!)**
- Les tweets n√©gatifs contiennent **24% plus d'ellipses (...)**
- Les tweets n√©gatifs sont l√©g√®rement plus longs et contiennent plus de mots

Cette analyse nous a permis de mieux comprendre les sp√©cificit√©s du langage sur Twitter et d'identifier des √©l√©ments discriminants entre sentiments positifs et n√©gatifs. Ces observations ont directement influenc√© notre strat√©gie de pr√©traitement et la conception de nos mod√®les.

### Pr√©traitement des donn√©es textuelles

En nous basant sur l'analyse exploratoire, nous avons d√©velopp√© une fonction de pr√©traitement sp√©cifique pour les tweets :

```python
def preprocess_tweet(tweet):
    """
    Pr√©traite un tweet en appliquant plusieurs transformations :
    - Conversion en minuscules
    - Remplacement des URLs, mentions et hashtags par des tokens sp√©ciaux
    - Suppression des caract√®res sp√©ciaux
    - Tokenisation et lemmatisation
    - Suppression des stopwords
    """
    # V√©rifier si le tweet est une cha√Æne de caract√®res
    if not isinstance(tweet, str):
        return ""
    
    # Convertir en minuscules
    tweet = tweet.lower()
    
    # Remplacer les URLs par un token sp√©cial
    tweet = re.sub(r'https?://\S+|www\.\S+', '<URL>', tweet)
    
    # Remplacer les mentions par un token sp√©cial
    tweet = re.sub(r'@\w+', '<MENTION>', tweet)
    
    # Traiter les hashtags (conserver le # comme token s√©par√© et le mot qui suit)
    tweet = re.sub(r'#(\w+)', r'# \1', tweet)
    
    # Supprimer les caract√®res sp√©ciaux et les nombres, mais garder les tokens sp√©ciaux
    tweet = re.sub(r'[^\w\s<>@#!?]', '', tweet)
    
    # Tokenisation
    tokens = word_tokenize(tweet)
    
    # Lemmatisation
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    
    # Supprimer les stopwords, mais conserver les n√©gations importantes
    stop_words = set(stopwords.words('english'))
    important_words = {'no', 'not', 'nor', 'neither', 'never', 'nobody', 'none', 'nothing', 'nowhere'}
    stop_words = stop_words - important_words
    tokens = [token for token in tokens if token not in stop_words]
    
    # Rejoindre les tokens en une cha√Æne
    return ' '.join(tokens)
```

Notre strat√©gie de pr√©traitement s'est concentr√©e sur trois aspects cl√©s :

1. **Traitement des √©l√©ments sp√©ciaux** : Plut√¥t que de simplement supprimer les URLs, mentions et hashtags, nous les avons remplac√©s par des tokens sp√©ciaux (`<URL>`, `<MENTION>`) afin de pr√©server l'information de leur pr√©sence, tout en s√©parant les hashtags pour conserver leur contenu s√©mantique.

2. **Conservation des n√©gations** : Nous avons exclu les mots de n√©gation de la liste des stopwords pour pr√©server le sens du sentiment exprim√©.

3. **Lemmatisation plut√¥t que stemming** : Apr√®s avoir test√© les deux approches, nous avons privil√©gi√© la lemmatisation qui pr√©serve mieux le sens des mots tout en r√©duisant la dimensionnalit√© du vocabulaire.

## üß† Approches de mod√©lisation

Pour r√©pondre √† la demande d'Air Paradis, nous avons d√©velopp√© et compar√© trois approches de mod√©lisation distinctes, de la plus simple √† la plus avanc√©e.

### Mod√®le sur mesure simple (approche classique)

Notre premi√®re approche s'est bas√©e sur des techniques classiques de machine learning, combinant une vectorisation du texte avec un classifieur traditionnel :

1. **Vectorisation** : transformation des textes en repr√©sentations num√©riques via TF-IDF (Term Frequency-Inverse Document Frequency)
2. **Classification** : utilisation d'une R√©gression Logistique pour pr√©dire la polarit√© du sentiment

Cette approche pr√©sente plusieurs avantages :
- Rapidit√© d'entra√Ænement et d'inf√©rence
- Faible empreinte m√©moire
- Bonne interpr√©tabilit√© des r√©sultats

Malgr√© sa simplicit√©, ce mod√®le a atteint une pr√©cision (accuracy) de 79,8% sur notre jeu de test, ce qui constitue une base solide pour la d√©tection de sentiments n√©gatifs.

### Mod√®le sur mesure avanc√© (r√©seaux de neurones avec word embeddings)

Pour notre deuxi√®me approche, nous avons explor√© les techniques de deep learning avec des embeddings de mots et des r√©seaux de neurones r√©currents. Nous avons d'abord optimis√© notre environnement pour utiliser efficacement le GPU disponible (GTX 1060 3GB) :

1. **Optimisations mat√©rielles** :
   - D√©sactivation du recurrent_dropout pour permettre l'utilisation de CuDNNLSTM optimis√©
   - Activation de XLA (Accelerated Linear Algebra) pour optimiser les graphes d'op√©rations
   - Utilisation de la pr√©cision mixte (float16/float32)
   - Augmentation de la taille du batch √† 256 pour exploiter le parall√©lisme
   - Optimisation du pipeline de donn√©es avec tf.data.Dataset et prefetch

2. **Word Embeddings** : nous avons compar√© deux techniques d'embeddings pour repr√©senter les mots dans un espace vectoriel dense :
   - Word2Vec pr√©-entra√Æn√© sur un large corpus de tweets
   - GloVe (Global Vectors for Word Representation)

3. **Architecture du r√©seau** : nous avons impl√©ment√© un r√©seau de neurones bidirectionnel avec plusieurs couches LSTM et des m√©canismes de r√©gularisation :

```python
def create_optimized_lstm_model(embedding_matrix, max_seq_length=MAX_SEQUENCE_LENGTH, trainable=False):
    vocab_size, embedding_dim = embedding_matrix.shape
    
    # Entr√©e du mod√®le
    input_layer = tf.keras.layers.Input(shape=(max_seq_length,))
    
    # Couche d'embedding avec des poids pr√©-entra√Æn√©s
    embedding_layer = tf.keras.layers.Embedding(
        input_dim=vocab_size,
        output_dim=embedding_dim,
        weights=[embedding_matrix],
        input_length=max_seq_length,
        trainable=trainable
    )(input_layer)
    
    # Dropout spatial
    dropout_1 = tf.keras.layers.SpatialDropout1D(0.3)(embedding_layer)
    
    # Couche LSTM bidirectionnelle optimis√©e pour GPU
    lstm_layer = tf.keras.layers.Bidirectional(
        tf.keras.layers.LSTM(
            units=128,
            dropout=0.2,
            recurrent_dropout=0.0,  # Optimisation GPU
            return_sequences=True
        )
    )(dropout_1)
    
    # Deuxi√®me couche LSTM
    lstm_layer_2 = tf.keras.layers.Bidirectional(
        tf.keras.layers.LSTM(
            units=64,
            dropout=0.2,
            recurrent_dropout=0.0  # Optimisation GPU
        )
    )(lstm_layer)
    
    # Couche dense avec activation ReLU
    dense_1 = tf.keras.layers.Dense(64, activation='relu')(lstm_layer_2)
    dropout_2 = tf.keras.layers.Dropout(0.4)(dense_1)
    
    # Couche de sortie
    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(dropout_2)
    
    # Cr√©er et compiler le mod√®le
    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
    
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

L'architecture de notre mod√®le LSTM comprend :
- Une couche d'embedding initialis√©e avec les poids pr√©-entra√Æn√©s Word2Vec
- Un dropout spatial pour r√©duire la corr√©lation entre les features cons√©cutives
- Deux couches LSTM bidirectionnelles (128 puis 64 unit√©s) pour capturer les d√©pendances contextuelles
- Des couches de dropout pour la r√©gularisation et √©viter le surapprentissage
- Une couche dense interm√©diaire avec activation ReLU 
- Une couche de sortie avec activation sigmo√Øde pour la classification binaire

Les r√©sultats de l'entra√Ænement montrent une progression constante de l'accuracy, comme on peut le voir sur les graphiques ci-dessous :

![Courbe d'apprentissage](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/48j9lz9bh84os9nkp2bz.png)

Cette approche plus sophistiqu√©e nous a permis d'atteindre une pr√©cision de 81,8% sur l'ensemble de validation, avec un score de 85,2% sur le jeu d'entra√Ænement, surpassant ainsi le mod√®le simple.

### Mod√®le BERT (approche transformer)

Pour notre troisi√®me approche, nous avons explor√© l'√©tat de l'art en NLP en utilisant BERT (Bidirectional Encoder Representations from Transformers) :

1. **Mod√®le pr√©-entra√Æn√©** : nous avons utilis√© DistilBERT, une version all√©g√©e et distill√©e de BERT, pour r√©duire les co√ªts de calcul tout en maintenant des performances √©lev√©es
2. **Fine-tuning** : nous avons affin√© le mod√®le sur notre jeu de donn√©es sp√©cifique d'analyse de sentiments

Pour cette approche, nous avons utilis√© le mod√®le `DistilBertForSequenceClassification` de la biblioth√®que Hugging Face, qui est sp√©cifiquement con√ßu pour les t√¢ches de classification de s√©quences textuelles :

```python
def train_bert_sentiment(data_path, model_name="distilbert-base-uncased", batch_size=4, epochs=3, sample_size=20000):
    """
    Fonction principale pour l'entra√Ænement du mod√®le DistilBERT sur une t√¢che d'analyse de sentiments.
    """

    # D√©finir les param√®tres
    params = {
        'model_name': model_name,
        'batch_size': batch_size,
        'learning_rate': 2e-5,
        'epochs': epochs,
        'max_length': 128,
        'sample_size': sample_size
    }

    # Charger les donn√©es
    print("Chargement du dataset...")
    column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']
    raw_data = pd.read_csv(data_path, encoding='utf-8', names=column_names)

    # Pr√©parer les donn√©es
    print("Pr√©paration des donn√©es...")
    data_splits = prepare_data(raw_data, sample_size=sample_size)

    # Initialiser le tokenizer et le mod√®le
    print("Initialisation du mod√®le DistilBERT...")
    tokenizer = DistilBertTokenizer.from_pretrained(model_name)
    model = DistilBertForSequenceClassification.from_pretrained(
        model_name,
        num_labels=2  # Sentiment binaire (0 = n√©gatif, 1 = positif)
    )

    # Ajustement du batch size selon la m√©moire GPU
    adjusted_batch_size = min(8, batch_size)
    
    # Cr√©ation des datasets et des dataloaders
    train_dataset = TweetDataset(data_splits['train']['texts'], data_splits['train']['labels'], tokenizer)
    val_dataset = TweetDataset(data_splits['val']['texts'], data_splits['val']['labels'], tokenizer)
    test_dataset = TweetDataset(data_splits['test']['texts'], data_splits['test']['labels'], tokenizer)

    train_loader = DataLoader(train_dataset, batch_size=adjusted_batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=adjusted_batch_size * 2)
    test_loader = DataLoader(test_dataset, batch_size=adjusted_batch_size * 2)

    # D√©tection du device (GPU/CPU)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    # Entra√Ænement du mod√®le avec accumulation de gradients pour optimiser l'utilisation m√©moire
    gradient_accumulation_steps = max(1, 16 // adjusted_batch_size)
    history, metrics = train_model(
        model,
        train_loader,
        val_loader,
        test_loader,
        device,
        epochs=epochs,
        gradient_accumulation_steps=gradient_accumulation_steps
    )

    # Enregistrement du mod√®le dans MLflow
    run_id = log_model_to_mlflow(model, tokenizer, model_name, metrics, params)

    return {
        'model': model,
        'tokenizer': tokenizer,
        'metrics': metrics,
        'run_id': run_id
    }
```

DistilBERT est particuli√®rement adapt√© √† notre t√¢che car il :
- Utilise une **architecture transformer bidirectionnelle** pour capturer le contexte dans les deux directions
- A √©t√© **pr√©-entra√Æn√© sur un large corpus de textes**, ce qui lui permet de comprendre les nuances linguistiques
- Est **40% plus l√©ger que BERT** tout en conservant 97% de ses performances
- S'int√®gre parfaitement dans un **pipeline MLOps** gr√¢ce √† son API standardis√©e

Cette approche **transformers** nous a permis d'atteindre une **pr√©cision de 91,3 %**, d√©montrant la puissance des **architectures bas√©es sur l'attention** pour la compr√©hension du langage naturel.

### Comparaison des performances des mod√®les

Voici un r√©capitulatif des performances obtenues avec nos diff√©rentes approches :

| Mod√®le | Pr√©cision (Accuracy) | F1-Score | Temps d'entra√Ænement | Taille du mod√®le |
|--------|----------------------|----------|---------------------|-----------------|
| R√©gression Logistique + TF-IDF | 79,8% | 0,797 | ~5 minutes | ~15 MB |
| LSTM + Word2Vec | 85,2% | 0,851 | ~2 heures | ~90 MB |
| LSTM + GloVe | 84,7% | 0,846 | ~2 heures | ~88 MB |
| DistilBERT fine-tun√© | 91,3% | 0,912 | ~4 heures (GPU) | ~250 MB |

Pour le d√©ploiement en production, nous avons retenu le mod√®le **LSTM avec Word2Vec**, qui offre le meilleur compromis entre performance et ressources requises. Bien que DistilBERT ait obtenu de meilleurs r√©sultats, sa taille et ses exigences en termes de ressources de calcul le rendaient moins adapt√© √† un d√©ploiement sur une infrastructure Cloud gratuite.

## ‚öôÔ∏è Mise en ≈ìuvre du MLOps

### Principes du MLOps

**Le MLOps (Machine Learning Operations) est une m√©thodologie qui vise √† standardiser et √† automatiser le cycle de vie des mod√®les de machine learning**, de leur d√©veloppement √† leur d√©ploiement en production. Pour ce projet, nous avons mis en ≈ìuvre plusieurs principes cl√©s du MLOps :

1. **Reproductibilit√©** : environnement de d√©veloppement versionn√© et document√©
2. **Automatisation** : pipeline de d√©ploiement continu
3. **Monitoring** : suivi des performances du mod√®le en production
4. **Am√©lioration continue** : collecte de feedback et r√©entra√Ænement p√©riodique

Cette approche nous a permis de cr√©er une solution robuste et √©volutive pour Air Paradis.

### Tracking des exp√©rimentations avec MLFlow

Pour assurer une gestion efficace des exp√©rimentations, nous avons utilis√© [MLFlow](https://mlflow.org/docs/latest/index.html), un outil open-source sp√©cialis√© dans le **suivi et la gestion des mod√®les de machine learning** :

1. **Tracking des m√©triques** : pour chaque exp√©rimentation, nous avons enregistr√© automatiquement les param√®tres du mod√®le, les m√©triques de performance (accuracy, F1-score, pr√©cision, rappel) et les artefacts g√©n√©r√©s
2. **Centralisation des mod√®les** : tous les mod√®les entra√Æn√©s ont √©t√© stock√©s de mani√®re centralis√©e avec leurs m√©tadonn√©es
3. **Visualisation** : l'interface utilisateur de MLFlow nous a permis de comparer visuellement les diff√©rentes exp√©rimentations

![Serveur MLFLow](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/btvbhmrrjepcj6cj6zw7.png)

Cette approche nous a permis de garder une trace claire de l'√©volution de nos mod√®les et de s√©lectionner objectivement le plus performant pour le d√©ploiement.

## üíª Interface utilisateur

### Architecture de l'application

Notre solution se compose de deux parties principales :

1. **Backend (FastAPI)** :
   - API REST exposant le mod√®le d'analyse de sentiments
   - Endpoints pour la pr√©diction individuelle et par lots
   - Syst√®me de feedback et de monitoring
   - T√©l√©chargement automatique des artefacts du mod√®le depuis MLFlow

![Page /docs du serveur FastAPI](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/telklwg14wd6h1q3jwk1.png)

2. **Frontend (Next.js)** :
   - Interface utilisateur intuitive et responsive
   - Mode clair/sombre pour le confort visuel
   - Visualisation des r√©sultats de pr√©diction
   - Syst√®me de collecte de feedback
   - Widget d'indication de connexion avec l'API

![Mockup macbook de l'application frontend](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/p9kesxlbg2d6tjod1xce.png)

### Fonctionnalit√©s de l'interface utilisateur

L'interface utilisateur offre plusieurs fonctionnalit√©s cl√©s pour faciliter l'analyse de sentiments :

1. **Analyse individuelle** : pr√©diction du sentiment d'un tweet unique
2. **Exemples pr√©d√©finis** : tweets d'exemple positifs et n√©gatifs
3. **Historique** : conservation des analyses pr√©c√©dentes
4. **Feedback** : possibilit√© de signaler des pr√©dictions incorrectes

Cette interface a √©t√© con√ßue pour √™tre **intuitive et accessible aux √©quipes marketing d'Air Paradis**, sans n√©cessiter de connaissances techniques approfondies.

## üîÑ Pipeline de d√©ploiement continu

Pour automatiser le d√©ploiement de notre mod√®le, nous avons mis en place un **pipeline CI/CD (Int√©gration Continue / D√©ploiement Continu)** avec les composants suivants :

1. **Versionnement du code** : utilisation de Git pour le contr√¥le de version
2. **GitHub Actions** : automatisation des tests et du d√©ploiement √† chaque push sur la branche principale
3. **D√©ploiement sur Heroku** : plateforme Cloud pour h√©berger notre API de pr√©diction

### Tests unitaires automatis√©s

Pour garantir la fiabilit√© de notre solution, nous avons impl√©ment√© des **tests unitaires automatis√©s** couvrant les aspects critiques :

1. **Test du endpoint de sant√©** : V√©rifie que l'API r√©pond correctement sur `/health` avec un code 200 et confirme que le statut retourn√© est "ok". Le mod√®le est charg√© correctement.
2. **Test du endpoint de pr√©diction** : S'assure que l'API traite correctement les requ√™tes POST sur `/predict`, accepte un texte √† analyser et renvoie un r√©sultat contenant les champs "sentiment" et "confidence".

```python
def test_health_endpoint(client):
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "ok"

def test_predict_endpoint(client):
    response = client.post("/predict", json={"text": "I love flying with this airline!"})
    assert response.status_code == 200
    result = response.json()
    assert "sentiment" in result
    assert "confidence" in result
```

### GitHub Actions 

Le d√©ploiement est enti√®rement automatis√© gr√¢ce √† **GitHub Actions** :

1. **D√©clenchement** : √Ä chaque commit/push sur la branche principale, GitHub Actions lance le workflow.
2. **Tests automatis√©s** : Le workflow ex√©cute tous les tests unitaires.
3. **D√©ploiement conditionnel** : Uniquement si les tests r√©ussissent, l'application est d√©ploy√©e automatiquement sur Heroku.

#### Cr√©ation du workflow GitHub Actions

Pour la cr√©ation du workflow GitHub Actions, nous cr√©ons un fichier `.github/workflows/heroku-deploy.yml` √† la racine dont voici le contenu :

```yaml
name: Deploy to Heroku

on:
  push:
    branches:
      - main
    paths:
      - 'app/fastapi/**'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        working-directory: ./app/fastapi
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run tests
        working-directory: ./app/fastapi
        run: |
          python -m pytest tests/test_api.py -v
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          RUN_ID: ${{ secrets.RUN_ID }}
          APPINSIGHTS_INSTRUMENTATION_KEY: ${{ secrets.APPINSIGHTS_INSTRUMENTATION_KEY }}

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Install Heroku CLI
        run: |
            curl https://cli-assets.heroku.com/install.sh | sh
      - name: Deploy to Heroku
        uses: akhileshns/heroku-deploy@v3.12.12
        with:
          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}
          heroku_app_name: "air-paradis-sentiment-api"
          heroku_email: ${{ secrets.HEROKU_EMAIL }}
          appdir: "app/fastapi"
          region: "eu"
```

#### Configuration des secrets GitHub

Le workflow **GitHub Actions** a besoin d'acc√©der aux **variables d'environnement**. Nous avons donc renseigner les "secrets" n√©cessaires. Dans notre d√©p√¥t GitHub, nous allons dans "Settings" > "Secrets and variables" > "Actions", puis nous cliquons sur "New repository secret". Nous ajoutons les secrets suivants:

| Nom du secret | Description |
|---------------|-------------|
| `HEROKU_API_KEY` | Cl√© API Heroku |
| `HEROKU_EMAIL` | Email du compte Heroku |
| `MLFLOW_TRACKING_URI` | URI du serveur MLflow |
| `RUN_ID` | ID du run MLflow |
| `APPINSIGHTS_INSTRUMENTATION_KEY` | Cl√© Application Insights |

### D√©ploiement sur Heroku

Pour le d√©ploiement de notre solution, nous avons choisi [Heroku](https://www.heroku.com/) pour plusieurs raisons :

1. **Plan gratuit** : conforme √† la demande de limiter les co√ªts pour ce prototype
2. **Int√©gration avec GitHub** : facilite le d√©ploiement continu avec GitHub Actions
3. **Scalabilit√©** : possibilit√© d'√©voluer si le projet est approuv√© pour la production
4. **R√©gion Europe** : conformit√© avec les exigences de localisation des donn√©es

#### Configuration Heroku

Notre application utilise les fichiers de configuration suivants pour Heroku :

- **Procfile** : `web: uvicorn main:app --host=0.0.0.0 --port=${PORT:-8000}`
- **runtime.txt** : `python-3.10.12`
- **requirements.txt** : Liste de toutes les d√©pendances n√©cessaires

Les variables d'environnement sur Heroku incluent :
- `MLFLOW_TRACKING_URI` : URI du serveur MLflow
- `RUN_ID` : Identifiant du run MLflow du mod√®le d√©ploy√©
- `APPINSIGHTS_INSTRUMENTATION_KEY` : Cl√© pour Azure Application Insights

### Exemple d'ex√©cution et d√©ploiement r√©ussis

La capture d'√©cran suivante indique les **tests ont √©t√© pass√©s avec succ√®s** et que le d√©ploiement est r√©ussi sur **Heroku**.

![Capture d'√©cran d'un run GitHub Actions](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/f8kea1d9cidmc6bp272r.png)

### Avantages de notre pipeline CI/CD

Notre pipeline de d√©ploiement continu offre plusieurs avantages significatifs :

1. **Automatisation compl√®te** : Aucune intervention manuelle n√©cessaire
2. **Fiabilit√© accrue** : Tests syst√©matiques r√©duisant les risques
3. **Tra√ßabilit√©** : Chaque d√©ploiement li√© √† un commit Git sp√©cifique
4. **Feedback rapide** : Information imm√©diate en cas de probl√®me

Cette approche MLOps moderne nous permet de nous concentrer sur l'am√©lioration de notre mod√®le d'analyse de sentiment plut√¥t que sur les aspects op√©rationnels, tout en garantissant que chaque nouvelle version est correctement valid√©e avant la mise en production.

## üì° Suivi de la performance en production

### Mise en place d'Azure Application Insights

Pour assurer un suivi efficace des performances du mod√®le en production, nous avons int√©gr√© Azure Application Insights, un service d'analyse des performances applicatives :

1. **T√©l√©m√©trie** : collecte automatique des donn√©es de performance de l'API
2. **√âv√©nements personnalis√©s** : enregistrement d'√©v√©nements sp√©cifiques li√©s au mod√®le
3. **Visualisation** : tableaux de bord pour suivre l'√©volution des performances

Cette int√©gration nous permet de disposer d'une vision compl√®te du comportement de notre mod√®le en situation r√©elle.

### Syst√®me de feedback utilisateur

Un √©l√©ment cl√© de notre approche MLOps est la collecte de feedback utilisateur sur les pr√©dictions du mod√®le :

1. **Interface de validation** : pour chaque pr√©diction, l'utilisateur peut indiquer si elle est correcte ou non
2. **Collecte structur√©e** : enregistrement du tweet, de la pr√©diction initiale et de la correction √©ventuelle
3. **Stockage centralis√©** : toutes les donn√©es de feedback sont centralis√©es dans Azure Application Insights

Dans Azure Application Insights, pour consulter les **feedbacks de tweets incorrectement pr√©dits**, il suffit d'ex√©cuter la commande suivante : 

```kusto
customEvents
| where name == "model_feedback" and customDimensions.is_correct == "False"
| sort by timestamp desc
| project timestamp, 
        tweet = tostring(customDimensions.tweet), 
        prediction = tostring(customDimensions.prediction), 
        corrected_sentiment = tostring(customDimensions.corrected_sentiment)
```

![Feedbacks de tweets incorrectement pr√©dits ](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/59roizfuhudinm7fjfol.png)

Ce syst√®me permet de **constituer progressivement un corpus d'exemples difficiles qui serviront √† am√©liorer le mod√®le**. Ces exemples difficiles sont particuli√®rement pr√©cieux car ils repr√©sentent les cas limites o√π le mod√®le actuel √©choue, r√©v√©lant ainsi ses points faibles sp√©cifiques.

En collectant syst√©matiquement ces tweets mal classifi√©s, nous cr√©ons un **dataset enrichi qui cible pr√©cis√©ment les lacunes du mod√®le**. Cette approche d'apprentissage actif (*active learning*) est beaucoup plus efficace qu'une simple augmentation de donn√©es al√©atoire, car elle concentre les efforts d'am√©lioration sur les zones probl√©matiques.

### Configuration des alertes automatiques

Pour d√©tecter rapidement les probl√®mes potentiels, nous avons configur√© un **syst√®me d'alertes automatiques** :

1. **D√©finition du seuil** : d√©clenchement d'une alerte si **3 pr√©dictions incorrectes sont signal√©es dans un intervalle de 5 minutes**.
2. **Notification** : envoi d'un email aux responsables du projet.
3. **Suivi** : journalisation des alertes pour analyse ult√©rieure.

![Capture de l'√©cran alertes de Azure Application Insights](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/siytp14vvvye8ray3ax1.png)

Ce m√©canisme proactif permet √† l'√©quipe d'intervenir rapidement en cas de d√©gradation des performances du mod√®le.

### Strat√©gie d'am√©lioration continue du mod√®le

Pour garantir la pertinence du mod√®le dans le temps, nous d√©finissons une strat√©gie d'am√©lioration continue :

1. **Analyse p√©riodique** : examen mensuel des tweets mal pr√©dits pour identifier des patterns
2. **Enrichissement des donn√©es** : ajout des exemples difficiles au jeu d'entra√Ænement
3. **R√©entra√Ænement** : mise √† jour trimestrielle du mod√®le avec les nouvelles donn√©es
4. **D√©ploiement automatis√©** : mise en production de la nouvelle version via le pipeline CI/CD

Cette approche cyclique permet d'adapter le mod√®le √† l'√©volution du langage sur Twitter et aux sp√©cificit√©s des conversations concernant Air Paradis.

## üèÅ Conclusion

### R√©sultats obtenus

Ce projet nous a permis de d√©velopper un **prototype fonctionnel d'analyse de sentiments pour tweets**, r√©pondant pleinement aux attentes d'Air Paradis :

1. **Performance** : notre mod√®le **LSTM avec Word2Vec** atteint une pr√©cision de 85,2%, offrant une d√©tection fiable des sentiments n√©gatifs.
2. **D√©ploiement** : la solution est accessible via une API REST d√©ploy√©e sur Heroku.
3. **Interface** : une application ergonomique permet aux √©quipes marketing d'utiliser facilement le mod√®le.
4. **Monitoring** : un syst√®me complet de suivi et d'alertes garantit la d√©tection rapide des probl√®mes potentiels.

### Perspectives d'√©volution

Si ce prototype est valid√© par Air Paradis, plusieurs axes d'am√©lioration pourraient √™tre explor√©s :

1. **D√©ploiement du mod√®le BERT** : migration vers une infrastructure permettant d'exploiter les performances sup√©rieures de BERT
2. **Analyse en temps r√©el** : int√©gration avec l'API Twitter pour une surveillance continue
3. **Classification multi-classes** : distinction entre sentiments n√©gatifs, neutres et positifs
4. **Analyse th√©matique** : identification des sujets sp√©cifiques g√©n√©rant des sentiments n√©gatifs

### Avantages pour Air Paradis

Cette solution d'analyse de sentiments offre plusieurs avantages strat√©giques pour Air Paradis :

1. **D√©tection pr√©coce** : identification des bad buzz potentiels avant qu'ils ne prennent de l'ampleur
2. **R√©activit√©** : capacit√© √† intervenir rapidement sur les probl√®mes signal√©s
3. **Intelligence client** : meilleure compr√©hension des pr√©occupations et des attentes des clients
4. **Protection de l'image** : pr√©servation de la r√©putation de la compagnie sur les r√©seaux sociaux

En conclusion, ce projet illustre comment **les technologies d'IA, combin√©es √† une approche MLOps structur√©e, peuvent apporter une r√©elle valeur ajout√©e dans la gestion de la r√©putation en ligne d'une entreprise**. Air Paradis dispose d√©sormais d'un outil puissant pour anticiper et g√©rer efficacement sa pr√©sence sur les r√©seaux sociaux.