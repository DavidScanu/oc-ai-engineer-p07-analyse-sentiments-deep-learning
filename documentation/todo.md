# â˜‘ï¸ TODO

- ModÃ¨les : 
  - ModÃ¨le Bert : entraÃ®nement sur Colab (max_epochs) âœ”ï¸
  - Tableau de comparaison des modÃ¨les ğŸš§
- Frontend : Next.js âœ”ï¸
  - App Insights Widget
  - Afficher le tweet dans le rÃ©sultat de la prÃ©diction âœ”ï¸
- Readme.md âœ”ï¸
- Docker ğŸš§

## Suivi de la performance du modÃ¨le en production âœ”ï¸

Initier un suivi de la performance du modÃ¨le en production. Pour cela tu utiliseras un service Azure Application Insight. âœ”ï¸

- Pour remonter des traces des tweets qui seraient considÃ©rÃ©s par lâ€™utilisateur comme mal prÃ©dits : le texte du tweet et la prÃ©diction. âœ”ï¸
- Pour dÃ©clencher une alerte (envoi SMS ou mail) dans le cas dâ€™un nombre trop important de tweet mal prÃ©dits (par exemple 3 tweets mal prÃ©dits en lâ€™espace de 5 minutes). âœ”ï¸
- Prendre des captures d'Ã©cran de : 
  - Journaux Azure  âœ”ï¸
  - Email d'alerte âœ”ï¸
- PrÃ©senter une dÃ©marche qui pourrait Ãªtre mise en oeuvre pour lâ€™analyse de ces statistiques et lâ€™amÃ©lioration du modÃ¨le dans le temps. âœ”ï¸

## DÃ©ploiement ğŸš§

- Pipeline de dÃ©ploiement continu du modÃ¨le que tu auras choisi via une API (Git + Github + Heroku)
- IntÃ¨gre Ã©galement des tests unitaires automatisÃ©s (Github actions)

## Rapports

- ğŸ“º VidÃ©o dÃ©mo de l'appli (2 mins max) ğŸš§
- ğŸ–¼ï¸ PrÃ©sentation (MLOps life cycle) ğŸš§
- ğŸ“ Articles (Partie 1 et Partie 2) ğŸš§

## PrÃ©sentation 

- Contexte : projet rÃ©pond au besoin, vÃ©rifier ce que les clients disent du produit 
  - Avec l'API on pourrait automatiser la lecture des tweet avec @AirParadis ou #AirParadis
- Jeu de donnÃ©es 
- Analyse exploratoire 
- Modele simple
- ModÃ¨le AvancÃ©e
- ModÃ¨le BERT
- SchÃ©ma Architecture / MLOps : 
  - Notebook
  - MLFlow
  - FastAPI
  - Frontend
- DÃ©mo live / vidÃ©o 
  - PrÃ©diction
  - Feedback
  - Alertes
- Conclusion
