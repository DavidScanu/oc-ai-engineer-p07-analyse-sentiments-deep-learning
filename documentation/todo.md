# ☑️ TODO

- Modèle Bert : entraînement sur Colab (max_epochs) ✔️
- Frontend : Next.js ✔️
- Readme.md ✔️
- Docker 🚧

## Déploiement 

- Pipeline de déploiement continu du modèle que tu auras choisi via une API (Git + Github + Heroku)
- Intègre également des tests unitaires automatisés (Github actions)

## Suivi de la performance du modèle en production

Initier un suivi de la performance du modèle en production. Pour cela tu utiliseras un service Azure Application Insight.

- Pour remonter des traces des tweets qui seraient considérés par l’utilisateur comme mal prédits : le texte du tweet et la prédiction.
- Pour déclencher une alerte (envoi SMS ou mail) dans le cas d’un nombre trop important de tweet mal prédits (par exemple 3 tweets mal prédits en l’espace de 5 minutes).
- Présenter une démarche qui pourrait être mise en oeuvre pour l’analyse de ces statistiques et l’amélioration du modèle dans le temps.

## Rapports

- Présentation (MLOps life cycle) 🚧
- Articles (Partie 1 et Partie 2) 🚧