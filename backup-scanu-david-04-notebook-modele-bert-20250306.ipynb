{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 7 - R√©alisez une analyse de sentiments gr√¢ce au Deep Learning\n",
    "\n",
    "> üéì OpenClassrooms ‚Ä¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | üëã *√âtudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)\n",
    "\n",
    "## Partie 4 : Analyse de Sentiment de Tweets avec BERT\n",
    "\n",
    "Dans ce notebook, nous explorons l'analyse de sentiment de tweets en utilisant **BERT (Bidirectional Encoder Representations from Transformers)**, un mod√®le de deep learning √† la pointe de la technologie pour le traitement du langage naturel. Le dataset **Sentiment140** contient 1,6 million de tweets √©tiquet√©s (positifs ou n√©gatifs), ce qui en fait une excellente ressource pour entra√Æner notre mod√®le. Contrairement aux approches traditionnelles qui n√©cessitent une ing√©nierie de caract√©ristiques complexe, **BERT comprend le contexte bidirectionnel des mots**, ce qui est particuli√®rement utile pour capturer les subtilit√©s linguistiques des tweets comme l'ironie, les abr√©viations et les expressions idiomatiques propres aux r√©seaux sociaux.\n",
    "\n",
    "## √âtapes principales du projet :\n",
    "\n",
    "1. **Pr√©paration des donn√©es**\n",
    "   - Chargement du dataset Sentiment140\n",
    "   - Pr√©traitement sp√©cifique aux tweets (URLs, mentions, hashtags)\n",
    "   - Division en ensembles d'entra√Ænement/validation/test\n",
    "\n",
    "2. **Cr√©ation et entra√Ænement du mod√®le BERT**\n",
    "   - Initialisation du mod√®le pr√©-entra√Æn√© BERT\n",
    "   - Configuration des hyperparam√®tres d'entra√Ænement\n",
    "   - Entra√Ænement avec suivi des m√©triques (accuracy, loss)\n",
    "\n",
    "3. **√âvaluation des performances**\n",
    "   - Calcul des m√©triques (pr√©cision, rappel, F1-score, AUC)\n",
    "   - Visualisation de la matrice de confusion et de la courbe ROC\n",
    "   - Analyse d√©taill√©e des erreurs de classification\n",
    "\n",
    "4. **Int√©gration MLflow**\n",
    "   - Suivi des exp√©riences et des m√©triques\n",
    "   - Sauvegarde des artefacts (mod√®le, tokenizer, graphiques)\n",
    "   - Documentation des hyperparam√®tres pour reproductibilit√©\n",
    "\n",
    "5. **D√©ploiement et utilisation**\n",
    "   - Chargement du mod√®le sauvegard√©\n",
    "   - Cr√©ation d'une fonction de pr√©diction pour nouveaux tweets\n",
    "   - Tests sur un ensemble diversifi√© de tweets\n",
    "\n",
    "Ce notebook pr√©sente une solution compl√®te et industrialis√©e pour l'analyse de sentiment, de l'entra√Ænement √† l'√©valuation jusqu'au d√©ploiement, en suivant les meilleures pratiques de MLOps avec MLflow.\n",
    "\n",
    "## üìù Contexte\n",
    "\n",
    "Dans le cadre de ma formation d'AI Engineer chez OpenClassrooms, ce projet s'inscrit dans un sc√©nario professionnel o√π j'interviens en tant qu'ing√©nieur IA chez MIC (Marketing Intelligence Consulting), entreprise de conseil sp√©cialis√©e en marketing digital.\n",
    "\n",
    "Notre client, Air Paradis (compagnie a√©rienne), souhaite **anticiper les bad buzz sur les r√©seaux sociaux**. La mission consiste √† d√©velopper un produit IA permettant de **pr√©dire le sentiment associ√© √† un tweet**, afin d'am√©liorer la gestion de sa r√©putation en ligne.\n",
    "\n",
    "## ‚ö° Mission\n",
    "\n",
    "> D√©velopper un mod√®le d'IA permettant de pr√©dire le sentiment associ√© √† un tweet.\n",
    "\n",
    "Cr√©er un prototype fonctionnel d'un mod√®le d'**analyse de sentiments pour tweets** selon trois approches diff√©rentes :\n",
    "\n",
    "1. **Mod√®le sur mesure simple** : Approche classique (r√©gression logistique) pour une pr√©diction rapide\n",
    "2. **Mod√®le sur mesure avanc√©** : Utilisation de r√©seaux de neurones profonds avec diff√©rents word embeddings\n",
    "3. **Mod√®le avanc√© BERT** : Exploration de l'apport en performance d'un mod√®le BERT\n",
    "\n",
    "Cette mission implique √©galement la mise en ≈ìuvre d'une d√©marche MLOps compl√®te :\n",
    "- Utilisation de **MLFlow** pour le tracking des exp√©rimentations et le stockage des mod√®les\n",
    "- Cr√©ation d'un pipeline de d√©ploiement continu (Git + Github + plateforme Cloud)\n",
    "- Int√©gration de tests unitaires automatis√©s\n",
    "- Mise en place d'un suivi de performance en production via Azure Application Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Appareil CUDA: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import AdamW \n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Backend qui fonctionne dans tous les environnements\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import zipfile\n",
    "import requests\n",
    "import json\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration de MLflow avec les variables d'environnement\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Configuration explicite de MLflow\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "print(f\"MLflow Tracking URI: {mlflow_tracking_uri}\")\n",
    "\n",
    "# Configuration explicite des identifiants AWS\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key_id\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_access_key\n",
    "print(\"Identifiants AWS configur√©s\")\n",
    "\n",
    "# Cr√©er l'exp√©rience MLflow\n",
    "mlflow.set_experiment(\"OC Projet 7\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Define the URL and the local file path\n",
    "url = \"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip\"\n",
    "local_zip_path = \"./content/data/sentiment140.zip\"\n",
    "extract_path = \"./content/data\"\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    # Download the zip file\n",
    "    response = requests.get(url)\n",
    "    with open(local_zip_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    # Delete the zip file\n",
    "    os.remove(local_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le chemin vers le fichier CSV\n",
    "csv_file_path = './content/data/training.1600000.processed.noemoticon.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©traitement des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR√âTRAITEMENT DES TWEETS\n",
    "def preprocess_tweet_for_bert(tweet):\n",
    "    \"\"\"\n",
    "    Pr√©traite un tweet pour l'entra√Ænement BERT en conservant la structure naturelle\n",
    "    du langage mais en normalisant certains √©l√©ments sp√©cifiques aux r√©seaux sociaux.\n",
    "    \"\"\"\n",
    "    # V√©rifier si le tweet est une cha√Æne de caract√®res\n",
    "    if not isinstance(tweet, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remplacer les URLs par un token sp√©cial\n",
    "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', tweet)\n",
    "    \n",
    "    # Remplacer les mentions par un token sp√©cial\n",
    "    tweet = re.sub(r'@\\w+', '[USER]', tweet)\n",
    "    \n",
    "    # Normaliser les hashtags (conserver le hashtag comme entit√©)\n",
    "    tweet = re.sub(r'#(\\w+)', r'#\\1', tweet)\n",
    "    \n",
    "    # Normaliser les espaces multiples\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    \n",
    "    # Supprimer les caract√®res non imprimables et certains caract√®res sp√©ciaux inutiles\n",
    "    tweet = re.sub(r'[^\\x20-\\x7E]', '', tweet)\n",
    "    \n",
    "    # Nettoyer les espaces en d√©but et fin\n",
    "    tweet = tweet.strip()\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©parations des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR√âPARATION DES DONN√âES\n",
    "def prepare_data(df, sample_size=50000, random_state=42):\n",
    "    \"\"\"\n",
    "    Pr√©paration des donn√©es pour l'entra√Ænement BERT\n",
    "    \"\"\"\n",
    "    # Remappage des labels (0=n√©gatif, 4=positif) vers (0=n√©gatif, 1=positif)\n",
    "    df['target'] = df['target'].replace({0: 0, 4: 1})\n",
    "    \n",
    "    # Pr√©traitement des tweets\n",
    "    print(\"Pr√©traitement des tweets...\")\n",
    "    df['processed_text'] = df['text'].apply(preprocess_tweet_for_bert)\n",
    "    \n",
    "    # S√©lection d'un √©chantillon pour l'entra√Ænement\n",
    "    sample_data = df.sample(n=sample_size, random_state=random_state)\n",
    "    \n",
    "    # Division train/val/test\n",
    "    train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(\n",
    "        sample_data['processed_text'].values, \n",
    "        sample_data['target'].values,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        train_val_texts,\n",
    "        train_val_labels,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train': {'texts': train_texts, 'labels': train_labels},\n",
    "        'val': {'texts': val_texts, 'labels': val_labels},\n",
    "        'test': {'texts': test_texts, 'labels': test_labels}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CR√âATION D'UN DATASET PYTORCH\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenisation du texte\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION D'ENTRA√éNEMENT\n",
    "def train_model(model, train_loader, val_loader, test_loader, device, epochs=3, gradient_accumulation_steps=4):\n",
    "    \"\"\"\n",
    "    Entra√Æne le mod√®le BERT et retourne l'historique d'entra√Ænement\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le BERT √† entra√Æner\n",
    "        train_loader: DataLoader pour les donn√©es d'entra√Ænement\n",
    "        val_loader: DataLoader pour les donn√©es de validation\n",
    "        test_loader: DataLoader pour les donn√©es de test\n",
    "        device: Device sur lequel ex√©cuter l'entra√Ænement (cuda/cpu)\n",
    "        epochs: Nombre d'√©poques d'entra√Ænement\n",
    "        gradient_accumulation_steps: Nombre de pas pour accumuler les gradients\n",
    "    \"\"\"\n",
    "    # Param√®tres d'optimisation\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "    \n",
    "    # Initialiser le scaler pour la pr√©cision mixte\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Scheduler pour adapter le learning rate\n",
    "    # Ajuster pour tenir compte de l'accumulation de gradient\n",
    "    total_steps = (len(train_loader) // gradient_accumulation_steps) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Historique d'entra√Ænement\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Boucle d'entra√Ænement\n",
    "    for epoch in range(epochs):\n",
    "        # Mode d'entra√Ænement\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_true = [], []\n",
    "        train_progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} (Training)')\n",
    "        \n",
    "        # Reset des gradients au d√©but de l'√©poque\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        for batch_idx, batch in enumerate(train_progress_bar):\n",
    "            # D√©placer les tenseurs sur le device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass avec pr√©cision mixte\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "            \n",
    "            # Calculer la perte et l'ajuster pour l'accumulation de gradient\n",
    "            loss = outputs.loss / gradient_accumulation_steps\n",
    "            train_loss += loss.item() * gradient_accumulation_steps  # Ajuster pour le reporting\n",
    "            \n",
    "            # Backward pass avec pr√©cision mixte\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Mise √† jour des poids seulement √† chaque √©tape d'accumulation\n",
    "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                # Clip gradient norm\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                # Optimizer step avec pr√©cision mixte\n",
    "                scaler.step(optimizer)\n",
    "                scheduler.step()\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # R√©cup√©ration des pr√©dictions\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "            \n",
    "            train_preds.extend(preds)\n",
    "            train_true.extend(true)\n",
    "            \n",
    "            # Mise √† jour de la barre de progression\n",
    "            train_progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "        \n",
    "        # Calcul de l'accuracy d'entra√Ænement\n",
    "        train_accuracy = accuracy_score(train_true, train_preds)\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Ajouter √† l'historique\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs} - Average training loss: {avg_train_loss:.3f}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Training accuracy: {train_accuracy:.3f}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_true = [], []\n",
    "        val_progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} (Validation)')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_progress_bar:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # R√©cup√©ration des pr√©dictions\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                true = labels.cpu().numpy()\n",
    "                \n",
    "                val_preds.extend(preds)\n",
    "                val_true.extend(true)\n",
    "                \n",
    "                # Mise √† jour de la barre de progression\n",
    "                val_progress_bar.set_postfix({'validation_loss': '{:.3f}'.format(loss.item())})\n",
    "        \n",
    "        # Calcul de l'accuracy de validation\n",
    "        val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Ajouter √† l'historique\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Validation loss: {avg_val_loss:.3f}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Validation accuracy: {val_accuracy:.3f}\")\n",
    "    \n",
    "    # √âvaluation finale sur le jeu de test\n",
    "    test_metrics = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    return history, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'√©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION D'√âVALUATION\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    √âvalue le mod√®le sur le jeu de test et retourne les m√©triques et pr√©dictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_preds, test_true = [], []\n",
    "    test_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"√âvaluation sur le jeu de test\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # R√©cup√©ration des pr√©dictions et probabilit√©s\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "            \n",
    "            test_preds.extend(preds)\n",
    "            test_true.extend(true)\n",
    "            test_probs.extend(probs[:, 1].cpu().numpy())  # Probabilit√© de la classe positive\n",
    "    \n",
    "    # Calcul des m√©triques\n",
    "    accuracy = accuracy_score(test_true, test_preds)\n",
    "    precision = precision_score(test_true, test_preds)\n",
    "    recall = recall_score(test_true, test_preds)\n",
    "    f1 = f1_score(test_true, test_preds)\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(test_true, test_preds)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(test_true, test_preds, target_names=['N√©gatif', 'Positif'])\n",
    "    \n",
    "    # Courbe ROC et AUC\n",
    "    fpr, tpr, _ = roc_curve(test_true, test_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Regrouper toutes les m√©triques\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'predictions': test_preds,\n",
    "        'true_labels': test_true,\n",
    "        'probabilities': test_probs\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR TRACER LA MATRICE DE CONFUSION\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Tracer la matrice de confusion\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Pr√©dictions')\n",
    "    plt.ylabel('Valeurs r√©elles')\n",
    "    plt.title('Matrice de confusion')\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour tracer l'historique d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR TRACER L'HISTORIQUE D'ENTRA√éNEMENT\n",
    "def plot_training_history(history, model_name, run_id=None):\n",
    "    \"\"\"\n",
    "    Trace l'historique d'entra√Ænement du mod√®le et l'enregistre dans MLflow\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Tracer l'accuracy\n",
    "    ax1.plot(history['train_accuracy'], label='train')\n",
    "    ax1.plot(history['val_accuracy'], label='validation')\n",
    "    ax1.set_title(f'Accuracy - {model_name}')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Tracer la loss\n",
    "    ax2.plot(history['train_loss'], label='train')\n",
    "    ax2.plot(history['val_loss'], label='validation')\n",
    "    ax2.set_title(f'Loss - {model_name}')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Sauvegarder la figure localement\n",
    "    os.makedirs('content/bert-model', exist_ok=True)\n",
    "    filename = f'content/bert-model/training_history_{model_name}.png'\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "    # Enregistrer dans MLflow en utilisant l'ex√©cution existante\n",
    "    if run_id:\n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            mlflow.log_figure(fig, f\"training_history_{model_name}.png\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour tracer la courbe ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR TRACER LA COURBE ROC\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, model_name, run_id=None):\n",
    "    \"\"\"\n",
    "    Trace la courbe ROC et l'enregistre dans MLflow\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taux de faux positifs')\n",
    "    plt.ylabel('Taux de vrais positifs')\n",
    "    plt.title(f'Courbe ROC - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Sauvegarder la figure localement\n",
    "    filename = f'content/bert-model/roc_curve_{model_name}.png'\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "    # Enregistrer dans MLflow en utilisant l'ex√©cution existante\n",
    "    if run_id:\n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            mlflow.log_figure(plt.gcf(), f\"roc_curve_{model_name}.png\")\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement du mod√®le dans MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR ENREGISTRER LE MOD√àLE DANS MLFLOW\n",
    "def log_model_to_mlflow(model, tokenizer, model_name, metrics, params=None):\n",
    "    \"\"\"\n",
    "    Enregistre le mod√®le et ses performances dans MLflow\n",
    "    \"\"\"\n",
    "    class_names = ['N√©gatif', 'Positif']\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"Model_Bert_{model_name}\"):\n",
    "        # Enregistrer les param√®tres du mod√®le\n",
    "        if params:\n",
    "            for key, value in params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "        \n",
    "        # Enregistrer les m√©triques de performance\n",
    "        mlflow.log_metric(\"accuracy\", metrics['accuracy'])\n",
    "        mlflow.log_metric(\"precision\", metrics['precision'])\n",
    "        mlflow.log_metric(\"recall\", metrics['recall'])\n",
    "        mlflow.log_metric(\"f1\", metrics['f1'])\n",
    "        mlflow.log_metric(\"roc_auc\", metrics['roc_auc'])\n",
    "        \n",
    "        # Tracer et enregistrer la matrice de confusion\n",
    "        fig_cm = plot_confusion_matrix(metrics['confusion_matrix'], class_names)\n",
    "        mlflow.log_figure(fig_cm, f\"confusion_matrix_{model_name}.png\")\n",
    "        \n",
    "        # Tracer et enregistrer la courbe ROC\n",
    "        fig_roc = plot_roc_curve(metrics['fpr'], metrics['tpr'], metrics['roc_auc'], model_name)\n",
    "        mlflow.log_figure(fig_roc, f\"roc_curve_{model_name}.png\")\n",
    "        \n",
    "        # Enregistrer le rapport de classification\n",
    "        report_path = f\"content/bert-model/classification_report.txt\"\n",
    "        os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(metrics['classification_report'])\n",
    "        mlflow.log_artifact(report_path)\n",
    "        \n",
    "        # Sauvegarder le mod√®le localement\n",
    "        model_path = f\"content/bert-model/model\"\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "        \n",
    "        # Sauvegarder les m√©triques\n",
    "        metrics_path = f\"content/bert-model/metrics.json\"\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            # Ne pas sauvegarder les arrays numpy car ils ne sont pas JSON serializable\n",
    "            metrics_json = {\n",
    "                k: v for k, v in metrics.items() \n",
    "                if k not in ['fpr', 'tpr', 'predictions', 'true_labels', 'probabilities', 'confusion_matrix']\n",
    "            }\n",
    "            # Pour les arrays numpy, convertir en listes\n",
    "            metrics_json['confusion_matrix'] = metrics['confusion_matrix'].tolist()\n",
    "            json.dump(metrics_json, f)\n",
    "        mlflow.log_artifact(metrics_path)\n",
    "        \n",
    "        # Enregistrer le mod√®le dans MLflow\n",
    "        mlflow.pytorch.log_model(\n",
    "            model, \n",
    "            f\"model_{model_name}\",\n",
    "            conda_env={\n",
    "                'name': 'bert_env',\n",
    "                'channels': ['defaults', 'pytorch', 'huggingface'],\n",
    "                'dependencies': [\n",
    "                    'python=3.8',\n",
    "                    'pytorch',\n",
    "                    'transformers'\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Enregistrer le tokenizer comme artefact\n",
    "        tokenizer_path = f\"content/bert-model/tokenizer\"\n",
    "        os.makedirs(tokenizer_path, exist_ok=True)\n",
    "        tokenizer.save_pretrained(tokenizer_path)\n",
    "        mlflow.log_artifact(tokenizer_path, \"tokenizer\")\n",
    "        \n",
    "        return mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION PRINCIPALE D'ENTRA√éNEMENT\n",
    "def train_bert_sentiment(data_path, model_name=\"DistilBERT-base\", batch_size=4, epochs=3, sample_size=20000):\n",
    "    \"\"\"\n",
    "    Fonction principale pour l'entra√Ænement du mod√®le BERT\n",
    "    \"\"\"\n",
    "    # D√©finir les param√®tres\n",
    "    params = {\n",
    "        'model_name': model_name,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': epochs,\n",
    "        'max_length': 128,\n",
    "        'sample_size': sample_size\n",
    "    }\n",
    "    \n",
    "    # Charger les donn√©es\n",
    "    print(\"Chargement du dataset...\")\n",
    "    column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "    raw_data = pd.read_csv(data_path, encoding='latin-1', names=column_names)\n",
    "    \n",
    "    # Pr√©parer les donn√©es\n",
    "    print(\"Pr√©paration des donn√©es...\")\n",
    "    data_splits = prepare_data(raw_data, sample_size=sample_size)\n",
    "    \n",
    "    # Initialiser le tokenizer et le mod√®le\n",
    "    print(\"Initialisation du mod√®le BERT...\")\n",
    "    # Utiliser DistilBERT qui est plus l√©ger pour les GPUs avec m√©moire limit√©e (comme GTX 1060 3GB)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased',\n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    # Cr√©ation des datasets et dataloaders\n",
    "    # Utiliser un batch_size plus petit pour les GPUs avec m√©moire limit√©e\n",
    "    print(\"Pr√©paration des dataloaders...\")\n",
    "    adjusted_batch_size = min(8, batch_size)  # R√©duire le batch size pour GTX 1060 3GB\n",
    "    print(f\"Batch size ajust√© √† {adjusted_batch_size} pour √©conomiser la m√©moire GPU\")\n",
    "    \n",
    "    train_dataset = TweetDataset(data_splits['train']['texts'], data_splits['train']['labels'], tokenizer)\n",
    "    val_dataset = TweetDataset(data_splits['val']['texts'], data_splits['val']['labels'], tokenizer)\n",
    "    test_dataset = TweetDataset(data_splits['test']['texts'], data_splits['test']['labels'], tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=adjusted_batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=adjusted_batch_size * 2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=adjusted_batch_size * 2)\n",
    "    \n",
    "    # D√©tection du device (GPU/CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Utilisation de: {device}\")\n",
    "    \n",
    "    # D√©placement du mod√®le sur le device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Entra√Ænement du mod√®le\n",
    "    print(\"D√©but de l'entra√Ænement...\")\n",
    "    # Ajouter gradient_accumulation_steps pour compenser la r√©duction du batch size\n",
    "    gradient_accumulation_steps = 4\n",
    "    print(f\"Utilisation de l'accumulation de gradient avec {gradient_accumulation_steps} √©tapes\")\n",
    "    \n",
    "    history, metrics = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        test_loader, \n",
    "        device,\n",
    "        epochs=epochs,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps\n",
    "    )\n",
    "    \n",
    "    # Enregistrer dans MLflow\n",
    "    print(\"Enregistrement dans MLflow...\")\n",
    "    run_id = log_model_to_mlflow(model, tokenizer, model_name, metrics, params)\n",
    "    \n",
    "    # Tracer et enregistrer l'historique d'entra√Ænement\n",
    "    plot_training_history(history, model_name, run_id)\n",
    "    \n",
    "    # Retourner le mod√®le entrain√© et le tokenizer\n",
    "    return {\n",
    "        'model': model,\n",
    "        'tokenizer': tokenizer,\n",
    "        'metrics': metrics,\n",
    "        'run_id': run_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Æner le mod√®le\n",
    "bert_pack = train_bert_sentiment(\n",
    "    data_path=csv_file_path,\n",
    "    model_name=\"DistilBERT-base\",\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    sample_size=50000  # Utiliser un √©chantillon plus grand si vous avez assez de m√©moire\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR CHARGER LE MOD√àLE ENTRAIN√â\n",
    "def load_bert_model(model_dir=\"content/bert-model/model\"):\n",
    "    \"\"\"\n",
    "    Charge le mod√®le BERT entra√Æn√© et le tokenizer\n",
    "    \"\"\"\n",
    "    # Charger le mod√®le et le tokenizer\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_dir)\n",
    "    \n",
    "    # Charger les m√©triques si disponibles\n",
    "    metrics_path = f\"content/bert-model/metrics.json\"\n",
    "    if os.path.exists(metrics_path):\n",
    "        with open(metrics_path, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "    else:\n",
    "        metrics = None\n",
    "    \n",
    "    # Cr√©ation d'un pack pour faciliter l'utilisation\n",
    "    model_pack = {\n",
    "        'model': model,\n",
    "        'tokenizer': tokenizer,\n",
    "        'metrics': metrics,\n",
    "        'preprocess': preprocess_tweet_for_bert\n",
    "    }\n",
    "    \n",
    "    return model_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de pr√©diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION DE PR√âDICTION\n",
    "def predict_sentiment(tweet, model_pack):\n",
    "    \"\"\"\n",
    "    Pr√©dit le sentiment d'un tweet √† l'aide du mod√®le BERT\n",
    "    \"\"\"\n",
    "    model = model_pack['model']\n",
    "    tokenizer = model_pack['tokenizer']\n",
    "    preprocess = model_pack['preprocess']\n",
    "    \n",
    "    # Pr√©traitement du tweet\n",
    "    processed_tweet = preprocess(tweet)\n",
    "    \n",
    "    # Tokenisation\n",
    "    encoding = tokenizer(\n",
    "        processed_tweet,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # D√©tection du device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Passer au mode √©valuation\n",
    "    model.eval()\n",
    "    \n",
    "    # D√©placer les tenseurs sur le device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Pr√©diction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    \n",
    "    # R√©cup√©rer le sentiment pr√©dit et le score de confiance\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    confidence_score = probabilities[0][predicted_class].item()\n",
    "    raw_score = probabilities[0][1].item()  # Score de la classe positive\n",
    "    \n",
    "    # Convertir en √©tiquette lisible\n",
    "    sentiment = \"Positif\" if predicted_class == 1 else \"N√©gatif\"\n",
    "    \n",
    "    # R√©sultat\n",
    "    result = {\n",
    "        'sentiment': sentiment,\n",
    "        'confidence': confidence_score,\n",
    "        'raw_score': raw_score\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sur un ensemble de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION DE TEST SUR ENSEMBLE DE TWEETS\n",
    "def test_model_on_examples(model_pack, test_tweets):\n",
    "    \"\"\"\n",
    "    Teste le mod√®le sur une liste de tweets et retourne un DataFrame avec les r√©sultats des pr√©dictions.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"Positif\": 0,\n",
    "        \"N√©gatif\": 0\n",
    "    }\n",
    "    \n",
    "    # Cr√©er un DataFrame pour stocker les r√©sultats\n",
    "    predictions_data = []\n",
    "    \n",
    "    for i, tweet in enumerate(test_tweets):\n",
    "        # Utiliser la fonction predict_sentiment avec model_pack\n",
    "        result = predict_sentiment(tweet, model_pack)\n",
    "        \n",
    "        # Ajouter l'emoji appropri√© pour le sentiment\n",
    "        emoji = \"üíö\" if result['sentiment'] == \"Positif\" else \"‚ùå\"\n",
    "        \n",
    "        # Ajouter les donn√©es au DataFrame\n",
    "        predictions_data.append({\n",
    "            \"Tweet\": tweet,\n",
    "            \"Sentiment\": result['sentiment'],\n",
    "            \"Emoji\": emoji,\n",
    "            \"Score de confiance\": result['confidence'],\n",
    "            \"Score brut\": result['raw_score'],\n",
    "            \"Index\": i+1\n",
    "        })\n",
    "        \n",
    "        # Comptage des r√©sultats\n",
    "        results[result['sentiment']] += 1\n",
    "    \n",
    "    # Cr√©er le DataFrame\n",
    "    df_predictions = pd.DataFrame(predictions_data)\n",
    "    \n",
    "    # Afficher un r√©sum√©\n",
    "    print(\"\\nTest du mod√®le sur les exemples:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"R√©sum√©: {len(test_tweets)} tweets analys√©s\")\n",
    "    print(f\"Tweets positifs: {results['Positif']} ({(results['Positif']/len(test_tweets)*100):.1f}%)\")\n",
    "    print(f\"Tweets n√©gatifs: {results['N√©gatif']} ({(results['N√©gatif']/len(test_tweets)*100):.1f}%)\")\n",
    "\n",
    "    # Sauvegarder les r√©sultats dans un fichier CSV\n",
    "    os.makedirs('content/bert-model', exist_ok=True)\n",
    "    df_predictions.to_csv(\"content/bert-model/predictions_results.csv\", index=False)\n",
    "\n",
    "    # Retourner le DataFrame\n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste am√©lior√©e de tweets pour tester le mod√®le\n",
    "test_tweets_improved = [\n",
    "    # Tweets positifs avec diff√©rentes caract√©ristiques\n",
    "    \"I absolutely love flying with @AirParadis! Their service is amazing and their staff is so helpful :) #bestairline #travel\",\n",
    "    \"Just landed after a wonderful flight... The crew was totally awesome and the food was perfect!!! Can't wait to fly with them again :D\",\n",
    "    \"OMG! You really have to try @AirParadis. Best. Flight. Ever. Their new seats are extremely comfortable. http://airparadis.com/newseats #travel #comfort\",\n",
    "    \"We had a very pleasant experience with our flight today. The staff completely exceeded our expectations ;) #happy #AirParadis\",\n",
    "    \"My first time flying business class and I'm absolutely amazed!!! The service is 100% worth it... @AirParadis never disappoints :)\",\n",
    "    \n",
    "    # Tweets n√©gatifs avec diff√©rentes caract√©ristiques\n",
    "    \"I hate how @AirParadis always delays their flights... This is the third time this month!!! :( #disappointed #travel\",\n",
    "    \"The worst flight experience of my life? Definitely today with @AirParadis. Their customer service won't even respond to my complaints... #terrible\",\n",
    "    \"Really @AirParadis??? Flight cancelled and no compensation??? That's how you treat your customers? SMH :(\",\n",
    "    \"Our baggage was lost and nobody at @AirParadis seems to care! Don't they understand that we can't enjoy our vacation without our stuff??? http://badservice.com/complaint :-(\",\n",
    "    \"Food was terrible, seats were uncomfortable, and the staff was not helpful at all... Never flying with @AirParadis again! #worstairline\",\n",
    "    \n",
    "    # Tweets mixtes et nuanc√©s\n",
    "    \"The flight was good but the food wasn't really what I expected... @AirParadis can do better! #mixedfeelings\",\n",
    "    \"IDK what to think about my @AirParadis experience? The crew was nice but the flight was delayed for 2 hours... #confused\",\n",
    "    \"My husband loved the flight but I didn't... Too bad they can't make everyone happy :-) #AirParadis\",\n",
    "    \"TBH, @AirParadis has improved their service since last year! Not perfect yet, but they're trying... #progress\",\n",
    "    \"We were so excited for our trip but then our flight got delayed... at least the staff was very apologetic and gave us free drinks! @AirParadis\"\n",
    "]\n",
    "\n",
    "# Charger le mod√®le entra√Æn√©\n",
    "model_pack = load_bert_model()\n",
    "\n",
    "# Tester le mod√®le sur les exemples\n",
    "df_results = test_model_on_examples(model_pack, test_tweets_improved)\n",
    "\n",
    "print(\"Analyse de sentiment termin√©e! R√©sultats disponibles dans content/bert-model/predictions_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
